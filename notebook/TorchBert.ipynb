{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    },
    "colab_type": "code",
    "id": "lA0BbXCIphJn",
    "outputId": "f43fddec-ebd2-49ab-8371-95ba80918ee8"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import logging as log\n",
    "\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "from transformers.models.bert.modeling_bert import BertEmbeddings, BertModel, BertPreTrainedModel\n",
    "from transformers import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    filename='bert.log')\n",
    "logger = log.getLogger('bert.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FN0GUySc2zxf",
    "outputId": "864a3b2a-0a26-490e-b7f1-384bd0b2c962"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla K80'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions to load/save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QT2HeFPduMzG"
   },
   "outputs": [],
   "source": [
    "root_folder = '../bert'\n",
    "\n",
    "def save_model(model, model_filename, folder=root_folder):\n",
    "    ''' Save a pytorch model '''\n",
    "    model_file = os.path.join(folder, model_filename)\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        os.remove(model_file)\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "\n",
    "def load_model(folder, version):\n",
    "    ''' Load a pytorch model '''\n",
    "    config_filename = f'config_{version}.pkl'  \n",
    "\n",
    "    with open(os.path.join(folder, config_filename), 'rb') as f:\n",
    "        config = pickle.load(f)\n",
    "\n",
    "    config.output_hidden_states = True\n",
    "    model = BertForMultiLabelSequenceClassification(config)\n",
    "\n",
    "    file = os.path.join(folder, f'bert_{version}_cuda.pt')\n",
    "    state = torch.load(file) if is_cuda else torch.load(file, map_location=lambda storage, loc: storage)\n",
    "\n",
    "    if is_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    return model\n",
    "\n",
    "def remove_last_model(folder, model_filename, config_filename):\n",
    "    model_file = os.path.join(folder, model_filename)\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        os.remove(model_file)\n",
    "\n",
    "    config_file = os.path.join(folder, config_filename)\n",
    "\n",
    "    if os.path.exists(config_file):\n",
    "        os.remove(config_file)\n",
    "\n",
    "def file_exists(filename, folder=root_folder):\n",
    "    return os.path.exists(os.path.join(folder, filename))\n",
    "\n",
    "def save_object(filename, obj, folder=root_folder):\n",
    "    obj_file = os.path.join(folder, filename)\n",
    "\n",
    "    if os.path.exists(obj_file):\n",
    "        os.remove(obj_file)\n",
    "\n",
    "    with open(obj_file, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_object(filename, folder=root_folder):\n",
    "    object_file = os.path.join(folder, filename)\n",
    "\n",
    "    with open(object_file, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "z3fJqCe-puL0",
    "outputId": "4a25ad99-56da-4a04-be00-46d0f29b974e"
   },
   "outputs": [],
   "source": [
    "model_class = BertModel\n",
    "tokenizer_class = BertTokenizer\n",
    "pretrained_weights = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EiiqXq9M8ieC"
   },
   "outputs": [],
   "source": [
    "class BertForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
    "    \"\"\"BERT model for multiple label classification.\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
    "        num_labels = len(label_columns)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
    "        self.loss_fct = BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, return_dict=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        if labels is not None: \n",
    "            # Training the model                \n",
    "            return self.loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "        \n",
    "        else:\n",
    "            #return hidden, pooled_output, logits\n",
    "            return logits\n",
    "            \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input (text) processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPPFrVtV996R"
   },
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, labels=None):\n",
    "        \"\"\"Constructs a InputExample.\"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.labels = labels\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUKr9OU59-PE"
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, label_list, max_seq_length):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    features = []\n",
    "    count = 0\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "    for example in examples:\n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "\n",
    "        if len(tokens_a) > max_seq_length - 2:\n",
    "            tokens_a = tokens_a[:(max_seq_length - 2)]\n",
    "\n",
    "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
    "        segment_ids = [0] * len(tokens)\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "        \n",
    "        labels_ids = [float(label) for label in example.labels]\n",
    "        features.append(InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_ids=labels_ids))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GZjUNwB3aRl"
   },
   "outputs": [],
   "source": [
    "# Load the full dataset into a DataFrame\n",
    "df = pd.read_parquet('../data/nyt.2000.parquet.gz')\n",
    "SEED = 17\n",
    "train, test = train_test_split(df, test_size=.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Uq4Q6rD_3lJV",
    "outputId": "e4be128b-2ebc-4952-8230-34cd07d46fc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25716\n",
      "6430\n"
     ]
    }
   ],
   "source": [
    "print(len(train.Id))\n",
    "print(len(test.Id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ZG2AW2naOOmT",
    "outputId": "d0ec60cc-3e8b-4fe0-cd17-e2b7d3fc7258"
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 80\n",
    "label_columns = [c for c in train.columns if c not in ['Id', 'Text']]\n",
    "\n",
    "def get_labels(data, i):\n",
    "    return data.iloc[i][label_columns]\n",
    "\n",
    "def create_features(data, max_seq_length=MAX_SEQ_LENGTH):\n",
    "    ''' Create the features for the BERT model '''\n",
    "    \n",
    "    print('Processing labels')\n",
    "    #label_list = [get_labels(data, i) for i in range(len(data))]\n",
    "    label_list = data[label_columns].values.tolist()\n",
    "    print('Processing examples')\n",
    "    examples = [InputExample(i, data.iloc[i].Text, labels=label_list[i]) for i in range(len(data))]\n",
    "    print('Converting examples to features')\n",
    "\n",
    "    return convert_examples_to_features(examples, label_list, max_seq_length)\n",
    "\n",
    "def get_features(data, filename):\n",
    "    ''' Create the features to the model '''\n",
    "    if file_exists(filename):\n",
    "        # Use the cached features if it exists\n",
    "        features = load_object(filename)\n",
    "    else:\n",
    "        # Create and save the features\n",
    "        features = create_features(data)\n",
    "        save_object(filename, features)\n",
    "\n",
    "    return features\n",
    "\n",
    "train_features = get_features(train, 'train_bert_features.pkl')\n",
    "test_features = get_features(test, 'test_bert_features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPqLF-ikWCAW"
   },
   "outputs": [],
   "source": [
    "batch_num = 32\n",
    "\n",
    "def create_input_ids_tensor(data_features):\n",
    "    return torch.tensor([i.input_ids for i in data_features])\n",
    "\n",
    "def create_input_masks_tensor(data_features):\n",
    "    return torch.tensor([i.input_mask for i in data_features])\n",
    "\n",
    "def create_segment_ids_tensor(data_features):\n",
    "    return torch.tensor([i.segment_ids for i in data_features])\n",
    "\n",
    "def create_label_ids_tensor(data_features):\n",
    "    return torch.tensor([i.label_ids for i in data_features])\n",
    "\n",
    "def create_data_loader(data_features, batch_size=batch_num, drop_last=True, shuffle=True):\n",
    "    dataset = TensorDataset(\n",
    "      create_input_ids_tensor(data_features),\n",
    "      create_input_masks_tensor(data_features),\n",
    "      create_segment_ids_tensor(data_features),\n",
    "      create_label_ids_tensor(data_features))\n",
    "    sampler = RandomSampler(dataset)\n",
    "\n",
    "    return DataLoader(dataset, sampler=sampler, batch_size=batch_size,drop_last=drop_last) if shuffle else DataLoader(dataset, batch_size=batch_size,drop_last=drop_last, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lGl6pNGteBoJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMultiLabelSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
       "  (loss_fct): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_weights = 'bert-base-uncased'\n",
    "model = BertForMultiLabelSequenceClassification.from_pretrained(pretrained_weights, \n",
    "                                                                num_labels=len(train.columns) - 2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9mLA1Oug7iL"
   },
   "outputs": [],
   "source": [
    "# Set epoch and grad max num\n",
    "epochs = 5\n",
    "max_grad_norm = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yg9g2EWEhXWw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    betas: (0.9, 0.999)\n",
       "    correct_bias: True\n",
       "    eps: 1e-06\n",
       "    lr: 3e-05\n",
       "    weight_decay: 0.0\n",
       "    weight_decay_rate: 0.01\n",
       "\n",
       "Parameter Group 1\n",
       "    betas: (0.9, 0.999)\n",
       "    correct_bias: True\n",
       "    eps: 1e-06\n",
       "    lr: 3e-05\n",
       "    weight_decay: 0.0\n",
       "    weight_decay_rate: 0.0\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine tune model all layer parameters\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "      'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "      'weight_decay_rate': 0.0}\n",
    "]\n",
    "    \n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Y0goKuhf_K7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMultiLabelSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
       "  (loss_fct): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the model for training\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "def calculate_loss(model):\n",
    "    ''' Calculate the loss on the test set for the model '''\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        num_examples = 0\n",
    "\n",
    "        for steps, batch in enumerate(create_data_loader(test_features)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            batch_input_ids, batch_input_masks, batch_segment_ids, batch_labels = batch\n",
    "            loss = model(batch_input_ids, batch_segment_ids, batch_input_masks, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "            num_examples += batch_input_ids.size(0)\n",
    "\n",
    "        return total_loss / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "excBpkTgiHHo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 1/5 [12:20<49:22, 740.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.005696094878757857, test loss: 0.00383337990147993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 2/5 [24:47<37:12, 744.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0030592881320833064, test loss: 0.003307192341890186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 3/5 [37:16<24:52, 746.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.002304647696957776, test loss: 0.0032738156637060456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 4/5 [49:45<12:27, 747.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.001754235030238309, test loss: 0.0036135375883895905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [1:02:14<00:00, 746.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0013261681446439678, test loss: 0.0038312167645199223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Main Training loop \n",
    "for epoch in trange(epochs,desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    num_examples, num_steps = 0, 0\n",
    "    \n",
    "    # Loop over the batches\n",
    "    for step, batch in enumerate(create_data_loader(train_features)):\n",
    "        logger.info(f'Starting step {step} from epoch {epoch}')\n",
    "        \n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_masks, b_segment_ids, b_labels = batch\n",
    "        outputs = model(b_input_ids, b_segment_ids, b_input_masks, b_labels)\n",
    "        loss = outputs\n",
    "        \n",
    "        if n_gpu>1:\n",
    "            # When multi gpu, average it\n",
    "            loss = loss.mean()\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        num_steps += 1\n",
    "        num_examples += b_input_ids.size(0)\n",
    "                \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        logger.info(f'Finished step {step}')\n",
    "    \n",
    "    # Accumulate the losses\n",
    "    train_losses.append(tr_loss / num_examples)\n",
    "    test_losses.append(calculate_loss(model))\n",
    "    \n",
    "    # Save the partial results\n",
    "    save_object('train_losses_bert.pkl', train_losses)\n",
    "    save_object('test_losses_bert.pkl', test_losses)\n",
    "    \n",
    "    # Display the losses for the epoch\n",
    "    logger.info(f'Train loss: {train_losses[-1]}, test loss: {test_losses[-1]}') \n",
    "    print(f'Train loss: {train_losses[-1]}, test loss: {test_losses[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYlo-OFWu4qx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='x'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'x':list(range(1, len(train_losses) + 1)), 'train':train_losses, 'test':test_losses}).plot(x='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4nuVx6o4vDBC"
   },
   "outputs": [],
   "source": [
    "def calculate_confusion_matrix(features, model, batch_size):\n",
    "    ''' Calculate the confusion matrix for the labels of the model '''\n",
    "    \n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(create_data_loader(features)):\n",
    "            # add batch to gpu\n",
    "            batch = tuple(t.to('cuda') for t in batch)\n",
    "            b_input_ids, b_input_masks, b_segment_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            raw_outputs = model(b_input_ids, b_segment_ids, b_input_masks)\n",
    "            predictions.append((torch.sigmoid(raw_outputs) > .5).cpu().numpy().astype(int))\n",
    "            true_labels.append(b_labels.cpu().numpy().astype(int))\n",
    "\n",
    "        true_labels = np.vstack(true_labels)[0:(batch_size * len(predictions)),]\n",
    "        predictions = np.vstack(predictions)\n",
    "\n",
    "        return (multilabel_confusion_matrix(true_labels, predictions),\n",
    "                true_labels,\n",
    "                predictions)\n",
    "    \n",
    "def print_pct_correct(features, model):\n",
    "    tmp = calculate_confusion_matrix(features, model, 80)\n",
    "    print(f'Percentage correct {((tmp[1] == tmp[2]).astype(int).sum(1) == 12).sum() / tmp[1].shape[0]}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwHSqhXwvG7I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct 0.9185476338729763\n"
     ]
    }
   ],
   "source": [
    "tmp = calculate_confusion_matrix(train_features, model, 80)\n",
    "print(f'Percentage correct {((tmp[1] == tmp[2]).astype(int).sum(1) == 12).sum() / tmp[1].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BlgUyxacvKVn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct 0.67265625\n"
     ]
    }
   ],
   "source": [
    "tmp = calculate_confusion_matrix(test_features, model, 80)\n",
    "print(f'Percentage correct {((tmp[1] == tmp[2]).astype(int).sum(1) == 12).sum() / tmp[1].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model, '../bert/bert.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename, folder=root_folder):\n",
    "    ''' Load a saved model '''\n",
    "    return torch.load(os.path.join(folder, filename))\n",
    "\n",
    "def calculate_confusion_matrix2(features, model, batch_size):\n",
    "    ''' Calculate the confusion matrix from a trained model '''\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(create_data_loader(features, batch_size, False, False)):\n",
    "            # add batch to gpu\n",
    "            if n_gpu != 0:\n",
    "                batch = tuple(t.to('cuda') for t in batch)\n",
    "            \n",
    "            logger.info(f'Step {step}')\n",
    "            b_input_ids, b_input_masks, b_segment_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            raw_outputs = model(b_input_ids, b_segment_ids, b_input_masks)\n",
    "            predictions.append((torch.sigmoid(raw_outputs[2]) > .5).cpu().numpy().astype(int))\n",
    "            true_labels.append(b_labels.cpu().numpy().astype(int))\n",
    "\n",
    "        true_labels = np.vstack(true_labels)[0:(batch_size * len(predictions)),]\n",
    "        predictions = np.vstack(predictions)\n",
    "\n",
    "        return (multilabel_confusion_matrix(true_labels, predictions),\n",
    "                true_labels,\n",
    "                predictions)\n",
    "\n",
    "def calculate_predictions(features, model, batch_size):\n",
    "    ''' Calculate the prediction from a trained model '''\n",
    "    \n",
    "    if n_gpu != 0:\n",
    "        model.cuda()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()\n",
    "    result = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(create_data_loader(features, batch_size, False, False)):\n",
    "            logger.info(f'Step {step}')\n",
    "            \n",
    "            # add batch to gpu\n",
    "            if n_gpu != 0:\n",
    "                batch = tuple(t.to('cuda') for t in batch)\n",
    "                \n",
    "            b_input_ids, b_input_masks, b_segment_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            raw_outputs = model(b_input_ids, b_segment_ids, b_input_masks)\n",
    "            predictions = torch.sigmoid(raw_outputs[2]).cpu()\n",
    "            predictions = predictions.numpy()\n",
    "            result = predictions if result is None else np.append(result, predictions, axis=0)\n",
    "            \n",
    "        return result\n",
    "\n",
    "def get_label_columns(data_frame):\n",
    "    ''' Return the columns with labels from the dataframe '''\n",
    "    return [c for c in data_frame.columns if c not in ('Id', 'Text') and '_Pred' not in c]\n",
    "\n",
    "def add_predictions(data_frame, features, model, batch_size):\n",
    "    ''' Calculate and add the predicted values to the dataframe '''\n",
    "    logits = calculate_predictions(features, model, batch_size)\n",
    "    predictions = (logits > .5).astype(int)\n",
    "    \n",
    "    for i, column_name in enumerate(get_label_columns(data_frame)):\n",
    "        data_frame[f'{column_name}_Pred'] = predictions[:, i]\n",
    "\n",
    "def add_predictions_to_dataframe(data_frame, predictions):\n",
    "    ''' Add the model prediction to the dataframe '''\n",
    "    for i, column_name in enumerate(get_label_columns(data_frame)):\n",
    "        data_frame[f'{column_name}_Pred'] = predictions[:, i]\n",
    "        \n",
    "class ModelResult:\n",
    "    ''' Helper class used to make prediction from a trained model '''\n",
    "    \n",
    "    def __init__(self, data_frame, features, model, batch_size):\n",
    "        confusion_matrix, labels, predictions = calculate_confusion_matrix(features, model, batch_size)\n",
    "        self.confusion_matrix = confusion_matrix\n",
    "        self.labels = labels\n",
    "        self.predictions = predictions\n",
    "        self.label_columns = get_label_columns(data_frame)\n",
    "        \n",
    "    def save(self, filename):\n",
    "        ''' Save the model results (this object) to disk '''\n",
    "        save_object(filename, self)\n",
    "        \n",
    "    def get_classification_report(self, output_dictionary):\n",
    "        ''' Return the classification report from the model predictions '''\n",
    "        return classification_report(self.labels, self.predictions, \n",
    "                                     target_names=self.label_columns, \n",
    "                                     output_dict=output_dictionary)\n",
    "        \n",
    "    def get_results_dataframe(self):\n",
    "        ''' Create a summary dataframe with the results from the model '''\n",
    "        report_dict = self.get_classification_report(True)\n",
    "        label_columns = list(self.label_columns)\n",
    "        label_columns.append('weighted avg')\n",
    "        classification_results = pd.DataFrame({'Label':label_columns})\n",
    "        classification_results['Precision'] = [report_dict[c]['precision'] for c in label_columns]\n",
    "        classification_results['Recall'] = [report_dict[c]['recall'] for c in label_columns]\n",
    "        classification_results['F1-Score'] = [report_dict[c]['f1-score'] for c in label_columns]\n",
    "        classification_results['Support'] = [report_dict[c]['support'] for c in label_columns]\n",
    "        classification_results.loc[classification_results['Label'] == 'weighted avg', 'Label'] = 'Weighted Average'\n",
    "        \n",
    "        return classification_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved model\n",
    "model = load_model('bert.pt', '../bert')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model_results = ModelResult(test, test_features, model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.save('bert_result_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_bert = load_object('bert_result_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6430"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400, 12)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('bert.pt', '../bert')\n",
    "model_results = ModelResult(test, test_features, model, 100)\n",
    "model_results.predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "add_predictions_to_dataframe(test[0:model_results.predictions.shape[0]], model_results.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test[get_label_columns(test)].sum(1).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World</td>\n",
       "      <td>0.772177</td>\n",
       "      <td>0.867497</td>\n",
       "      <td>0.817067</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.772973</td>\n",
       "      <td>0.756614</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New_York_and_Region</td>\n",
       "      <td>0.896896</td>\n",
       "      <td>0.888523</td>\n",
       "      <td>0.892690</td>\n",
       "      <td>1821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Front_Page</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.388112</td>\n",
       "      <td>0.470339</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business</td>\n",
       "      <td>0.892052</td>\n",
       "      <td>0.881594</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US</td>\n",
       "      <td>0.775971</td>\n",
       "      <td>0.755363</td>\n",
       "      <td>0.765528</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sports</td>\n",
       "      <td>0.967175</td>\n",
       "      <td>0.978068</td>\n",
       "      <td>0.972591</td>\n",
       "      <td>1687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Obituaries</td>\n",
       "      <td>0.974638</td>\n",
       "      <td>0.996296</td>\n",
       "      <td>0.985348</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Health</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.624585</td>\n",
       "      <td>0.682396</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Education</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.604938</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Science</td>\n",
       "      <td>0.713514</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.700265</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Technology</td>\n",
       "      <td>0.926230</td>\n",
       "      <td>0.801418</td>\n",
       "      <td>0.859316</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Weighted Average</td>\n",
       "      <td>0.841318</td>\n",
       "      <td>0.835939</td>\n",
       "      <td>0.837330</td>\n",
       "      <td>9210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Label  Precision    Recall  F1-Score  Support\n",
       "0                 World   0.772177  0.867497  0.817067      883\n",
       "1            Washington   0.740933  0.772973  0.756614      740\n",
       "2   New_York_and_Region   0.896896  0.888523  0.892690     1821\n",
       "3            Front_Page   0.596774  0.388112  0.470339      286\n",
       "4              Business   0.892052  0.881594  0.886792      853\n",
       "5                    US   0.775971  0.755363  0.765528     1958\n",
       "6                Sports   0.967175  0.978068  0.972591     1687\n",
       "7            Obituaries   0.974638  0.996296  0.985348      270\n",
       "8                Health   0.752000  0.624585  0.682396      301\n",
       "9             Education   0.583333  0.628205  0.604938       78\n",
       "10              Science   0.713514  0.687500  0.700265      192\n",
       "11           Technology   0.926230  0.801418  0.859316      141\n",
       "12     Weighted Average   0.841318  0.835939  0.837330     9210"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results.get_results_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Label'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_results.get_results_dataframe().plot.barh(x='Label', y=['Precision', 'Recall', 'F1-Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'x':((model_results.labels == model_results.predictions).astype(int).sum(1))}).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct 0.6532258064516129\n"
     ]
    }
   ],
   "source": [
    "tmp = calculate_confusion_matrix(test_features[0:1000], model, 80)\n",
    "print(f'Percentage correct {((tmp[1] == tmp[2]).astype(int).sum(1) == 12).sum() / tmp[1].shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ns2V0n20FRwh"
   },
   "source": [
    "## Saving the model\n",
    "\n",
    "* [pytorch](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
    "\n",
    "* [Google Drive](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=D78AM1fFt2ty)\n",
    "\n",
    "## Bert\n",
    "\n",
    "* [Bert Tutorial (Hidden Layers)](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/)\n",
    "\n",
    "* [GIT Huggingface](https://github.com/huggingface/transformers/blob/master/transformers/modeling_bert.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TorchBert 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
