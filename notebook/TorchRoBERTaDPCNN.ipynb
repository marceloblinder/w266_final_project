{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "Sz5dMqVoLWQA",
    "outputId": "8ae43beb-a0b1-4d9c-983e-91f00c2e11a5"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import logging as log\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "from transformers.models.bert.modeling_bert import BertEmbeddings, BertModel, BertPreTrainedModel\n",
    "from transformers import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    filename='bert.log')\n",
    "logger = log.getLogger('robert.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FN0GUySc2zxf",
    "outputId": "76915fd6-da91-4953-e73c-1c98331149fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla K80'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions to load and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SgJMUdJuCavo"
   },
   "outputs": [],
   "source": [
    "root_folder = '../roberta'\n",
    "\n",
    "def save_model(model, model_filename, folder=root_folder):\n",
    "    ''' Save a pytorch model '''\n",
    "    model_file = os.path.join(folder, model_filename)\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        os.remove(model_file)\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "\n",
    "def load_model(model_filename, folder=root_folder):\n",
    "    ''' Load a pytorch model '''\n",
    "    model_file = os.path.join(folder, model_filename)\n",
    "    model = torch.load(model_filename)\n",
    "\n",
    "    if is_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    return model\n",
    "\n",
    "def remove_last_model(folder, model_filename, config_filename):\n",
    "    model_file = os.path.join(folder, model_filename)\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        os.remove(model_file)\n",
    "\n",
    "    config_file = os.path.join(folder, config_filename)\n",
    "\n",
    "    if os.path.exists(config_file):\n",
    "        os.remove(config_file)\n",
    "\n",
    "def file_exists(filename, folder=root_folder):\n",
    "    return os.path.exists(os.path.join(folder, filename))\n",
    "\n",
    "def save_object(filename, obj, folder=root_folder):\n",
    "    obj_file = os.path.join(folder, filename)\n",
    "\n",
    "    if os.path.exists(obj_file):\n",
    "        os.remove(obj_file)\n",
    "\n",
    "    with open(obj_file, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_object(filename, folder=root_folder):\n",
    "    object_file = os.path.join(folder, filename)\n",
    "\n",
    "    with open(object_file, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RoBERTa model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "z3fJqCe-puL0",
    "outputId": "492ad161-0504-44d3-b55e-f671bf69d91d"
   },
   "outputs": [],
   "source": [
    "model_class = RobertaModel\n",
    "tokenizer_class = RobertaTokenizer\n",
    "pretrained_weights = 'roberta-base'\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input (text) processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPPFrVtV996R"
   },
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, labels=None):\n",
    "        \"\"\"Constructs a InputExample.\"\"\"\n",
    "        self.text_a = text_a\n",
    "        self.labels = labels\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, label_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.label_ids = label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUKr9OU59-PE"
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, label_list, tokenizer, max_seq_length):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    features = []\n",
    "    count = 0\n",
    "\n",
    "    for example in examples:\n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "        tokens_b = None\n",
    "\n",
    "        if len(tokens_a) > max_seq_length - 2:\n",
    "            tokens_a = tokens_a[:(max_seq_length - 2)]\n",
    "\n",
    "        tokens = ['<s>'] + tokens_a + ['</s>']\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        \n",
    "        labels_ids = [float(label) for label in example.labels]\n",
    "        input_features = InputFeatures(input_ids, labels_ids)\n",
    "        features.append(input_features)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GZjUNwB3aRl"
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/nyt.2000.parquet.gz')\n",
    "SEED = 17\n",
    "train, test = train_test_split(df, test_size=.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Uq4Q6rD_3lJV",
    "outputId": "0642bb9d-0978-47d7-b49e-f8579a6aeec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25716\n",
      "6430\n"
     ]
    }
   ],
   "source": [
    "print(len(train.Id))\n",
    "print(len(test.Id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZG2AW2naOOmT"
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 100\n",
    "label_columns = [c for c in train.columns if c not in ['Id', 'Text']]\n",
    "\n",
    "def get_labels(data, i):\n",
    "    return data.iloc[i][label_columns]\n",
    "\n",
    "def create_features(data, tokenizer, max_seq_length=MAX_SEQ_LENGTH):\n",
    "    logger.info('Processing labels')\n",
    "    label_list = data[label_columns].values.tolist()\n",
    "    logger.info('Processing examples')\n",
    "    examples = (InputExample(i, data.iloc[i].Text, labels=label_list[i]) for i in range(len(data)))\n",
    "    logger.info('Converting examples to features')\n",
    "\n",
    "    return convert_examples_to_features(examples, label_list, tokenizer, max_seq_length)\n",
    "\n",
    "def get_features(data, filename):\n",
    "    if file_exists(filename):\n",
    "        features = load_object(filename)\n",
    "    else:\n",
    "        tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "        features = create_features(data, tokenizer)\n",
    "        save_object(filename, features)\n",
    "\n",
    "    return features\n",
    "\n",
    "train_features = get_features(train, 'train_roberta_features.pkl')\n",
    "test_features = get_features(test, 'test_roberta_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4AjFtP_81D1"
   },
   "outputs": [],
   "source": [
    "class DPCNN(nn.Module):\n",
    "    def __init__(self, num_labels, channel_size=250, width=768):\n",
    "        super(DPCNN, self).__init__()\n",
    "        self.conv_embedding = nn.Conv2d(1, channel_size, (3, width))\n",
    "        self.conv2 = nn.Conv2d(channel_size, channel_size, (3, 1))\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=(3,1), stride=2)\n",
    "        self.padding_conv = nn.ZeroPad2d((0, 0, 1, 1))\n",
    "        self.padding_pool = nn.ZeroPad2d((0, 0, 0, 1))\n",
    "        self.activation_function = nn.ReLU()\n",
    "        self.last_linear = nn.Linear(channel_size, num_labels)\n",
    "        self.channel_size = channel_size\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        # Expected 4-dimensional input for 4-dimensional weight 3 1 3 768, but got 2-dimensional input of size [32, 768] instead\n",
    "        batch_size, width, height = embeddings.shape\n",
    "\n",
    "        # First transform the BERT embeddings (batch_size, num_characters, 768),\n",
    "        # like (64, 80, 768)\n",
    "        # to a 4D tensor like [64, 1, 80, 768] (required by the Conv2d)\n",
    "        x = embeddings.view((batch_size, 1, width, height))\n",
    "\n",
    "        # Run the first convolution (embedding). The output is [64, 250, 78, 1] \n",
    "        x = self.conv_embedding(x)\n",
    "        #print(f'1 {x.shape}')        \n",
    "        #x = self.activation_function(x)\n",
    "        x_save = x\n",
    "\n",
    "        # Run the second convolution. The output is [64, 250, 76, 1]\n",
    "        x = self.conv2(x)\n",
    "        #print(f'2 {x.shape}')\n",
    "\n",
    "        # Add padding at starting and ending rows of the tensor. After that the\n",
    "        # shape will be [64, 250, 78, 1]\n",
    "        x = self.padding_conv(x)\n",
    "        #x = self.activation_function(x)\n",
    "\n",
    "        # Run another convolution. After that the shape will be [64, 250, 76, 1]\n",
    "        x = self.conv2(x)\n",
    "        x = self.padding_conv(x)\n",
    "        x = x + self.activation_function(x_save)\n",
    "        #print(f'3 {x.shape}')\n",
    "\n",
    "        # Go over the blocks\n",
    "        while x.shape[-2] >= 2:\n",
    "            #print(x.shape)\n",
    "            x = self.padding_pool(x)\n",
    "            #print(f'3.1 {x.shape}')\n",
    "\n",
    "            # Save the pool output to add that to the convolutions at the end\n",
    "            pooling_x = self.pooling(x) \n",
    "            #print(f'pooling {pooling_x.shape}')\n",
    "\n",
    "            # Perform the first convolution\n",
    "            x = self.padding_conv(pooling_x)\n",
    "            x = nn.functional.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            #print(f'4 {x.shape}')\n",
    "\n",
    "            # Perform the second convolution\n",
    "            x = self.padding_conv(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            #print(f'5 {x.shape}')\n",
    "\n",
    "            # Do the addition \n",
    "            x = x + pooling_x\n",
    "\n",
    "        x = x.view(batch_size, self.channel_size)\n",
    "        x = self.last_linear(x)\n",
    "         \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p6o0cIOz2nyf"
   },
   "outputs": [],
   "source": [
    "class RoBERTaFull(nn.Module):\n",
    "    \"\"\"BERT model for multiple label classification.\"\"\"\n",
    "    def __init__(self, num_labels, hidden_dropout_prob=.5):\n",
    "        super(RoBERTaFull, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.loss_fct = BCEWithLogitsLoss()\n",
    "\n",
    "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.dropout = torch.nn.Dropout(hidden_dropout_prob)\n",
    "        self.dpcnn = DPCNN(num_labels)\n",
    "        self.classifier = torch.nn.Linear(num_labels, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, labels=None):\n",
    "        hidden, pooled_output = self.roberta(input_ids, return_dict=False)\n",
    "        x = self.dropout(hidden) # pooled_output\n",
    "        x = self.dpcnn(x)\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        if labels is not None: \n",
    "            # Training the model     \n",
    "            return self.loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "        \n",
    "        else:\n",
    "            return logits\n",
    "            \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loader for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPqLF-ikWCAW"
   },
   "outputs": [],
   "source": [
    "batch_num = 40 #48\n",
    "\n",
    "def create_input_ids_tensor(data_features):\n",
    "    return torch.tensor([i.input_ids for i in data_features])\n",
    "\n",
    "def create_input_masks_tensor(data_features):\n",
    "    return torch.tensor([i.input_mask for i in data_features])\n",
    "\n",
    "def create_segment_ids_tensor(data_features):\n",
    "    return torch.tensor([i.segment_ids for i in data_features])\n",
    "\n",
    "def create_label_ids_tensor(data_features):\n",
    "    return torch.tensor([i.label_ids for i in data_features])\n",
    "\n",
    "def create_data_loader(data_features, batch_size=batch_num, drop_last=True, shuffle=True):\n",
    "    dataset = TensorDataset(\n",
    "      create_input_ids_tensor(data_features),\n",
    "      create_label_ids_tensor(data_features))\n",
    "    sampler = RandomSampler(dataset)\n",
    "\n",
    "    return DataLoader(dataset, sampler=sampler, batch_size=batch_size,drop_last=drop_last) if shuffle else DataLoader(dataset, batch_size=batch_size,drop_last=drop_last, shuffle=shuffle)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lGl6pNGteBoJ",
    "outputId": "5b99b946-7416-4405-8ea4-c43dcc09f2d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoBERTaFull(\n",
       "  (loss_fct): BCEWithLogitsLoss()\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (dpcnn): DPCNN(\n",
       "    (conv_embedding): Conv2d(1, 250, kernel_size=(3, 768), stride=(1, 1))\n",
       "    (conv2): Conv2d(250, 250, kernel_size=(3, 1), stride=(1, 1))\n",
       "    (pooling): MaxPool2d(kernel_size=(3, 1), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (padding_conv): ZeroPad2d(padding=(0, 0, 1, 1), value=0.0)\n",
       "    (padding_pool): ZeroPad2d(padding=(0, 0, 0, 1), value=0.0)\n",
       "    (activation_function): ReLU()\n",
       "    (last_linear): Linear(in_features=250, out_features=12, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=12, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RoBERTaFull(len(train.columns) - 2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9mLA1Oug7iL"
   },
   "outputs": [],
   "source": [
    "# Set epoch and grad max num\n",
    "epochs = 2\n",
    "max_grad_norm = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Yg9g2EWEhXWw",
    "outputId": "6001ea12-9b73-44a9-d45b-400aef0a6380"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoBERTaFull(\n",
       "  (loss_fct): BCEWithLogitsLoss()\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (dpcnn): DPCNN(\n",
       "    (conv_embedding): Conv2d(1, 250, kernel_size=(3, 768), stride=(1, 1))\n",
       "    (conv2): Conv2d(250, 250, kernel_size=(3, 1), stride=(1, 1))\n",
       "    (pooling): MaxPool2d(kernel_size=(3, 1), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (padding_conv): ZeroPad2d(padding=(0, 0, 1, 1), value=0.0)\n",
       "    (padding_pool): ZeroPad2d(padding=(0, 0, 0, 1), value=0.0)\n",
       "    (activation_function): ReLU()\n",
       "    (last_linear): Linear(in_features=250, out_features=12, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=12, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine tune model all layer parameters\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "      'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "      'weight_decay_rate': 0.0}\n",
    "]\n",
    "    \n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Y0goKuhf_K7"
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "def calculate_loss(model):\n",
    "    ''' Calculate the loss on the test set for the model '''\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        num_examples = 0\n",
    "\n",
    "        for steps, batch in enumerate(create_data_loader(test_features)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            batch_input_ids, batch_labels = batch\n",
    "            loss = model(batch_input_ids, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "            num_examples += batch_input_ids.size(0)\n",
    "\n",
    "        return total_loss / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "excBpkTgiHHo",
    "outputId": "97ddea63-4755-444d-ebdc-37eb98539980"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.004289464152641478, test loss: 0.0027392586250789466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 1/2 [15:19<15:19, 919.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.002441031993816482, test loss: 0.002544004448573105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 2/2 [30:49<00:00, 924.60s/it]\n"
     ]
    }
   ],
   "source": [
    "# Main Training loop \n",
    "for i in trange(epochs,desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    num_examples, num_steps = 0, 0\n",
    "    \n",
    "    # Loop over the batches    \n",
    "    for step, batch in enumerate(create_data_loader(train_features)):\n",
    "        logger.info(f'Starting step {step}')\n",
    "        \n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_labels = batch\n",
    "        \n",
    "        # forward pass\n",
    "        outputs= model(b_input_ids, b_labels)\n",
    "        loss = outputs\n",
    "        \n",
    "        if n_gpu>1:\n",
    "            # When multi gpu, average it\n",
    "            loss = loss.mean()\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        num_examples += b_input_ids.size(0)\n",
    "        num_steps += 1\n",
    "        \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    # print train loss per epoch\n",
    "    train_losses.append(tr_loss / num_examples)\n",
    "    test_losses.append(calculate_loss(model))\n",
    "    save_object('train_losses_roberta_dpcnn.pkl', train_losses)\n",
    "    save_object('test_losses_roberta_dpcnn.pkl', test_losses)\n",
    "    \n",
    "    # Display the epoch results\n",
    "    logger.info(f'Train loss: {train_losses[-1]}, test loss: {test_losses[-1]}') \n",
    "    print(f'Train loss: {train_losses[-1]}, test loss: {test_losses[-1]}')\n",
    "    logger.info(f'Saving the model for the epoch {i}')\n",
    "    \n",
    "    # Save the model\n",
    "    save_model(model, 'roberta_dpcnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='x'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'x':list(range(1, len(train_losses) + 1)), 'train':train_losses, 'dev':test_losses}).plot(x='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confusion_matrix(features, model, batch_size):\n",
    "    ''' Calculate the confusion matrix for the labels of the model '''\n",
    "    \n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(create_data_loader(features)):\n",
    "            # add batch to gpu\n",
    "            batch = tuple(t.to('cuda') for t in batch)\n",
    "            b_input_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            raw_outputs = model(b_input_ids)\n",
    "            predictions.append((torch.sigmoid(raw_outputs) > .5).cpu().numpy().astype(int))\n",
    "            true_labels.append(b_labels.cpu().numpy().astype(int))\n",
    "\n",
    "        true_labels = np.vstack(true_labels)[0:(batch_size * len(predictions)),]\n",
    "        predictions = np.vstack(predictions)\n",
    "\n",
    "        return (multilabel_confusion_matrix(true_labels, predictions),\n",
    "                true_labels,\n",
    "                predictions)\n",
    "    \n",
    "def print_pct_correct(features, model):\n",
    "    tmp = calculate_confusion_matrix(features, model, 80)\n",
    "    print(f'Percentage correct {((tmp[1] == tmp[2]).astype(int).sum(1) == 12).sum() / tmp[1].shape[0]}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IYn6pn4A58nQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct 0.7281931464174455\n"
     ]
    }
   ],
   "source": [
    "print_pct_correct(train_features, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct 0.67390625\n"
     ]
    }
   ],
   "source": [
    "print_pct_correct(test_features, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename, folder=root_folder):\n",
    "    ''' Load the save model '''\n",
    "    \n",
    "    model = RoBERTaFull(len(train.columns) - 2)\n",
    "        \n",
    "    if n_gpu != 0:\n",
    "        state = torch.load(os.path.join(folder, filename))        \n",
    "        model.load_state_dict(state)        \n",
    "        model.cuda()\n",
    "    else:\n",
    "        state = torch.load(os.path.join(folder, filename), map_location=torch.device('cpu'))             \n",
    "        model.load_state_dict(state)\n",
    "      \n",
    "    return model\n",
    "\n",
    "def calculate_confusion_matrix(features, model, batch_size):\n",
    "    ''' Calculate the confusion matrix from a trained model '''\n",
    "    \n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(create_data_loader(features, batch_size, False, False)):\n",
    "            # add batch to gpu\n",
    "            if n_gpu != 0:\n",
    "                batch = tuple(t.to('cuda') for t in batch)\n",
    "            \n",
    "            logger.info(f'Step {step}')\n",
    "            b_input_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            raw_outputs = model(b_input_ids)\n",
    "            predictions.append((torch.sigmoid(raw_outputs) > .5).cpu().numpy().astype(int))\n",
    "            true_labels.append(b_labels.cpu().numpy().astype(int))\n",
    "\n",
    "        true_labels = np.vstack(true_labels)[0:(batch_size * len(predictions)),]\n",
    "        predictions = np.vstack(predictions)\n",
    "\n",
    "        return (multilabel_confusion_matrix(true_labels, predictions),\n",
    "                true_labels,\n",
    "                predictions)\n",
    "\n",
    "def calculate_predictions(features, model, batch_size):\n",
    "    ''' Calculate the prediction from a trained model '''\n",
    "    \n",
    "    if n_gpu != 0:\n",
    "        model.cuda()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()\n",
    "    result = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(create_data_loader(features, batch_size, False, False)):\n",
    "            logger.info(f'Step {step}')\n",
    "            \n",
    "            # add batch to gpu\n",
    "            if n_gpu != 0:\n",
    "                batch = tuple(t.to('cuda') for t in batch)\n",
    "                \n",
    "            b_input_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            raw_outputs = model(b_input_ids)\n",
    "            predictions = torch.sigmoid(raw_outputs[2]).cpu()\n",
    "            predictions = predictions.numpy()\n",
    "            result = predictions if result is None else np.append(result, predictions, axis=0)\n",
    "            \n",
    "        return result\n",
    "\n",
    "def get_label_columns(data_frame):\n",
    "    ''' Return the columns with labels from the dataframe '''\n",
    "    return [c for c in data_frame.columns if c not in ('Id', 'Text') and '_Pred' not in c]\n",
    "\n",
    "def add_predictions(data_frame, features, model, batch_size):\n",
    "    ''' Calculate and add the predicted values to the dataframe '''\n",
    "    \n",
    "    logits = calculate_predictions(features, model, batch_size)\n",
    "    predictions = (logits > .5).astype(int)\n",
    "    \n",
    "    for i, column_name in enumerate(get_label_columns(data_frame)):\n",
    "        data_frame[f'{column_name}_Pred'] = predictions[:, i]\n",
    "\n",
    "def add_predictions_to_dataframe(data_frame, predictions):\n",
    "    ''' Add the model prediction to the dataframe '''\n",
    "    \n",
    "    for i, column_name in enumerate(get_label_columns(data_frame)):\n",
    "        data_frame[f'{column_name}_Pred'] = predictions[:, i]\n",
    "        \n",
    "class ModelResult:\n",
    "    ''' Helper class used to make prediction from a trained model '''\n",
    "    \n",
    "    def __init__(self, data_frame, features, model, batch_size):\n",
    "        confusion_matrix, labels, predictions = calculate_confusion_matrix(features, model, batch_size)\n",
    "        self.confusion_matrix = confusion_matrix\n",
    "        self.labels = labels\n",
    "        self.predictions = predictions\n",
    "        self.label_columns = get_label_columns(data_frame)\n",
    "        \n",
    "    def save(self, filename):\n",
    "        ''' Save the model results (this object) to disk '''\n",
    "        save_object(filename, self)\n",
    "        \n",
    "    def get_classification_report(self, output_dictionary):\n",
    "        ''' Return the classification report from the model predictions '''\n",
    "        \n",
    "        return classification_report(self.labels, self.predictions, \n",
    "                                     target_names=self.label_columns, \n",
    "                                     output_dict=output_dictionary)\n",
    "        \n",
    "    def get_results_dataframe(self):\n",
    "        ''' Create a summary dataframe with the results from the model '''\n",
    "        \n",
    "        report_dict = self.get_classification_report(True)\n",
    "        label_columns = list(self.label_columns)\n",
    "        label_columns.append('weighted avg')\n",
    "        classification_results = pd.DataFrame({'Label':label_columns})\n",
    "        classification_results['Precision'] = [report_dict[c]['precision'] for c in label_columns]\n",
    "        classification_results['Recall'] = [report_dict[c]['recall'] for c in label_columns]\n",
    "        classification_results['F1-Score'] = [report_dict[c]['f1-score'] for c in label_columns]\n",
    "        classification_results['Support'] = [report_dict[c]['support'] for c in label_columns]\n",
    "        classification_results.loc[classification_results['Label'] == 'weighted avg', 'Label'] = 'Weighted Average'\n",
    "        \n",
    "        return classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('roberta_dpcnn.pt', '../roberta')\n",
    "model_results = ModelResult(test, test_features, model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.save('roberta_dpcnn_result_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = load_object('roberta_dpcnn_result_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-a2b666404bc3>:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[f'{column_name}_Pred'] = predictions[:, i]\n"
     ]
    }
   ],
   "source": [
    "add_predictions_to_dataframe(test, model_results.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test[get_label_columns(test)].sum(1).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World</td>\n",
       "      <td>0.777102</td>\n",
       "      <td>0.865688</td>\n",
       "      <td>0.819007</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington</td>\n",
       "      <td>0.770580</td>\n",
       "      <td>0.769542</td>\n",
       "      <td>0.770061</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New_York_and_Region</td>\n",
       "      <td>0.904185</td>\n",
       "      <td>0.898741</td>\n",
       "      <td>0.901455</td>\n",
       "      <td>1827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Front_Page</td>\n",
       "      <td>0.570707</td>\n",
       "      <td>0.395105</td>\n",
       "      <td>0.466942</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business</td>\n",
       "      <td>0.898053</td>\n",
       "      <td>0.912689</td>\n",
       "      <td>0.905312</td>\n",
       "      <td>859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US</td>\n",
       "      <td>0.779331</td>\n",
       "      <td>0.794402</td>\n",
       "      <td>0.786794</td>\n",
       "      <td>1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sports</td>\n",
       "      <td>0.981381</td>\n",
       "      <td>0.964581</td>\n",
       "      <td>0.972909</td>\n",
       "      <td>1694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Obituaries</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.996310</td>\n",
       "      <td>0.987203</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Health</td>\n",
       "      <td>0.671687</td>\n",
       "      <td>0.738411</td>\n",
       "      <td>0.703470</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Education</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.546584</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Science</td>\n",
       "      <td>0.844595</td>\n",
       "      <td>0.651042</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Technology</td>\n",
       "      <td>0.783439</td>\n",
       "      <td>0.860140</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Weighted Average</td>\n",
       "      <td>0.846320</td>\n",
       "      <td>0.849865</td>\n",
       "      <td>0.846988</td>\n",
       "      <td>9245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Label  Precision    Recall  F1-Score  Support\n",
       "0                 World   0.777102  0.865688  0.819007      886\n",
       "1            Washington   0.770580  0.769542  0.770061      742\n",
       "2   New_York_and_Region   0.904185  0.898741  0.901455     1827\n",
       "3            Front_Page   0.570707  0.395105  0.466942      286\n",
       "4              Business   0.898053  0.912689  0.905312      859\n",
       "5                    US   0.779331  0.794402  0.786794     1965\n",
       "6                Sports   0.981381  0.964581  0.972909     1694\n",
       "7            Obituaries   0.978261  0.996310  0.987203      271\n",
       "8                Health   0.671687  0.738411  0.703470      302\n",
       "9             Education   0.530120  0.564103  0.546584       78\n",
       "10              Science   0.844595  0.651042  0.735294      192\n",
       "11           Technology   0.783439  0.860140  0.820000      143\n",
       "12     Weighted Average   0.846320  0.849865  0.846988     9245"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results.get_results_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Label'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_results.get_results_dataframe().plot.barh(x='Label', y='Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'x':((model_results.labels == model_results.predictions).astype(int).sum(1))}).plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_train = ModelResult(train, train_features, model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_train.save('roberta_dpcnn_result_train.pkl')\n",
    "model_results_train = load_object('roberta_dpcnn_result_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_train.get_results_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_train.get_results_dataframe().plot.barh(x='Label', y='Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'x':((model_results.labels == model_results.predictions).astype(int).sum(1))}).plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ns2V0n20FRwh"
   },
   "source": [
    "## Saving the model\n",
    "\n",
    "* [pytorch](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
    "\n",
    "* [Google Drive](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=D78AM1fFt2ty)\n",
    "\n",
    "## Bert\n",
    "\n",
    "* [Bert Tutorial (Hidden Layers)](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/)\n",
    "\n",
    "* [GIT Huggingface](https://github.com/huggingface/transformers/blob/master/transformers/modeling_bert.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TorchBert 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
