{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15211,
     "status": "ok",
     "timestamp": 1574073950220,
     "user": {
      "displayName": "Carlos Sancini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBK_a0VL329YfM0B72acZH97KLpfXxCOtGUCi9s=s64",
      "userId": "02726390835148099400"
     },
     "user_tz": 180
    },
    "id": "pYIWtv8Z7YqN",
    "outputId": "7d28f119-158e-4dfd-98e1-ecd1367273b0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import logging as log\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification, XLNetConfig\n",
    "from transformers import AdamW\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "\n",
    "SEED = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H9FgNNg7k4Bc"
   },
   "outputs": [],
   "source": [
    "log.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    filename='xlnet_multilabel.log',\n",
    "                    level=log.INFO)\n",
    "logger = log.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JKBzbugJ4hOi"
   },
   "source": [
    "#### Setting up gpu environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1063,
     "status": "ok",
     "timestamp": 1574073951308,
     "user": {
      "displayName": "Carlos Sancini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBK_a0VL329YfM0B72acZH97KLpfXxCOtGUCi9s=s64",
      "userId": "02726390835148099400"
     },
     "user_tz": 180
    },
    "id": "m60T5Qio7LCs",
    "outputId": "0be6c8ed-a93f-41d5-c571-2e42b5aa1cd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla K80'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SAIjuU18JgNK"
   },
   "source": [
    "Preparing NYT dataset for *XLNet*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 91908,
     "status": "ok",
     "timestamp": 1574021269968,
     "user": {
      "displayName": "Carlos Sancini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBK_a0VL329YfM0B72acZH97KLpfXxCOtGUCi9s=s64",
      "userId": "02726390835148099400"
     },
     "user_tz": 180
    },
    "id": "tRXDaFimVyYO",
    "outputId": "62f9bf28-dd5e-462a-d8bb-33515c2e7970"
   },
   "outputs": [],
   "source": [
    "#from google.colab import auth\n",
    "import pandas as pd\n",
    "#auth.authenticate_user()\n",
    "df_full = pd.read_parquet('../data/nyt.2000.parquet.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 755,
     "status": "ok",
     "timestamp": 1574021270740,
     "user": {
      "displayName": "Carlos Sancini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBK_a0VL329YfM0B72acZH97KLpfXxCOtGUCi9s=s64",
      "userId": "02726390835148099400"
     },
     "user_tz": 180
    },
    "id": "0Rso1WmWelw3",
    "outputId": "8cd11477-1a95-4d28-f2dc-c10d0f44d4ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32146, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N71zwRkEn2-J"
   },
   "outputs": [],
   "source": [
    "# sample a small set of observations for testing \n",
    "#df = df_full.sample(10000, random_state=SEED)\n",
    "\n",
    "# full dataset for the real deal\n",
    "df = df_full\n",
    "\n",
    "df = df.set_index(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 967,
     "status": "ok",
     "timestamp": 1574021270971,
     "user": {
      "displayName": "Carlos Sancini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBK_a0VL329YfM0B72acZH97KLpfXxCOtGUCi9s=s64",
      "userId": "02726390835148099400"
     },
     "user_tz": 180
    },
    "id": "ccpWYcp5YHcH",
    "outputId": "be6ad6df-4ca3-4563-9c22-61e2fa5d7dd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>World</th>\n",
       "      <th>Washington</th>\n",
       "      <th>New_York_and_Region</th>\n",
       "      <th>Front_Page</th>\n",
       "      <th>Business</th>\n",
       "      <th>US</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Obituaries</th>\n",
       "      <th>Health</th>\n",
       "      <th>Education</th>\n",
       "      <th>Science</th>\n",
       "      <th>Technology</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1165059</th>\n",
       "      <td>The man accused of stabbing George Harrison on...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165110</th>\n",
       "      <td>Most nights, P. J. Sanchez, 9, comes into his ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165173</th>\n",
       "      <td>Of all the instincts in animals, the strongest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165189</th>\n",
       "      <td>THE Scarecrow in \"The Wizard of Oz\" wanted onl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165219</th>\n",
       "      <td>UNLIKE the sheep named Dolly, the mouse named ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Text  World  Washington  \\\n",
       "Id                                                                              \n",
       "1165059  The man accused of stabbing George Harrison on...      1           0   \n",
       "1165110  Most nights, P. J. Sanchez, 9, comes into his ...      0           0   \n",
       "1165173  Of all the instincts in animals, the strongest...      0           0   \n",
       "1165189  THE Scarecrow in \"The Wizard of Oz\" wanted onl...      0           0   \n",
       "1165219  UNLIKE the sheep named Dolly, the mouse named ...      0           0   \n",
       "\n",
       "         New_York_and_Region  Front_Page  Business  US  Sports  Obituaries  \\\n",
       "Id                                                                           \n",
       "1165059                    0           0         0   0       0           0   \n",
       "1165110                    1           0         0   0       0           0   \n",
       "1165173                    0           0         0   0       0           0   \n",
       "1165189                    0           0         0   0       0           0   \n",
       "1165219                    0           0         0   0       0           0   \n",
       "\n",
       "         Health  Education  Science  Technology  \n",
       "Id                                               \n",
       "1165059       1          0        0           0  \n",
       "1165110       1          0        0           0  \n",
       "1165173       1          0        0           0  \n",
       "1165189       1          0        0           0  \n",
       "1165219       1          0        0           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Health == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3439,
     "status": "ok",
     "timestamp": 1574073997945,
     "user": {
      "displayName": "Carlos Sancini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBK_a0VL329YfM0B72acZH97KLpfXxCOtGUCi9s=s64",
      "userId": "02726390835148099400"
     },
     "user_tz": 180
    },
    "id": "klfFFgooZsLC",
    "outputId": "1a6b74ae-0200-4bf1-dabf-750af213109b"
   },
   "outputs": [],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4349,
     "status": "ok",
     "timestamp": 1574021274370,
     "user": {
      "displayName": "Carlos Sancini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBK_a0VL329YfM0B72acZH97KLpfXxCOtGUCi9s=s64",
      "userId": "02726390835148099400"
     },
     "user_tz": 180
    },
    "id": "-Mc115VSyv1T",
    "outputId": "c323fe88-ce91-40d3-830e-7c20cd528e6c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(\n",
    "    [len(s) for s in df.sample(1000)[\"Text\"].apply(lambda x: tokenizer.tokenize(x))], \n",
    "    bins=[0, 128, 256, 512, 1024, 2048, 5096], \n",
    "    histtype='bar', \n",
    "    facecolor='b',\n",
    "    edgecolor='k',\n",
    "    alpha=0.5)\n",
    "plt.xticks([0, 128, 256, 512, 1024, 2048, 5096], rotation='vertical')\n",
    "plt.xlabel('Tokens')\n",
    "plt.ylabel('Sentences')\n",
    "plt.title('Histogram of number of tokens in sentences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2174909,
     "status": "ok",
     "timestamp": 1574023523372,
     "user": {
      "displayName": "Carlos Sancini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBK_a0VL329YfM0B72acZH97KLpfXxCOtGUCi9s=s64",
      "userId": "02726390835148099400"
     },
     "user_tz": 180
    },
    "id": "gDOAvSBj9jrP",
    "outputId": "7c436f98-7c5c-4408-a41e-ce86ea766246"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizer: 100%|██████████| 32146/32146 [01:10<00:00, 453.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# Sentences larger than MAX_LEN are truncated (out-of-memory workaround)\n",
    "MAX_LEN = 128\n",
    "\n",
    "df_input_ids_full = df[\"Text\"].copy()\n",
    "XLNET_END_TOKEN_IDS = tokenizer.encode(\"[SEP][CLS]\")\n",
    "\n",
    "for i in tqdm(df_input_ids_full.index, desc=\"Tokenizer\"):\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(\n",
    "        tokenizer.tokenize(df_input_ids_full[i])[:MAX_LEN - len(XLNET_END_TOKEN_IDS)])\n",
    "    df_input_ids_full.at[i] = input_ids + XLNET_END_TOKEN_IDS\n",
    "\n",
    "df_input_ids_full.shape\n",
    "# the code below causes out-of-memory crash and the code above was used\n",
    "\n",
    "# convert to XLNet vocabulary tokens\n",
    "df[\"tokens\"] = df[\"Text\"].apply(lambda x: tokenizer.tokenize(x + \" [SEP] [CLS]\"))\n",
    "\n",
    "# convert tokens to XLNet vocabulary ids\n",
    "df[\"input_ids_full\"] = df[\"tokens\"].apply(lambda x: tokenizer.convert_tokens_to_ids(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JABiS_MpzHg3"
   },
   "outputs": [],
   "source": [
    "# using Keras function to handle padding\n",
    "df[\"input_ids\"] = pad_sequences(\n",
    "    df_input_ids_full, \n",
    "    maxlen=MAX_LEN, \n",
    "    dtype=\"long\", \n",
    "    padding=\"post\", \n",
    "    value=0).tolist()\n",
    "\n",
    "# Create XLNet masks: 1 for tokens 0 for padding\n",
    "attention_masks = []\n",
    "for input_id in df.input_ids:\n",
    "    mask = [int(i>0) for i in input_id]\n",
    "    attention_masks.append(mask)\n",
    "df[\"attention_masks\"] = attention_masks\n",
    "\n",
    "# Create XLNet segments: 0 for each token of the first sentence, \n",
    "# followed by a 1 for each token of the second sentence.  For one sentence \n",
    "# inputs, this is simply a sequence of 0s\n",
    "df[\"segment_masks\"] = np.zeros((df.shape[0], MAX_LEN), dtype=int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1574023602658,
     "user": {
      "displayName": "Carlos Sancini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBK_a0VL329YfM0B72acZH97KLpfXxCOtGUCi9s=s64",
      "userId": "02726390835148099400"
     },
     "user_tz": 180
    },
    "id": "n3mCx93492k6",
    "outputId": "453e7f56-d3fb-4082-97f2-ce1a07a84cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 1165119\n",
      "The hijackers of an Indian Airlines plane won the release of three prominent militants jailed in India. All of them sped away from the airport in Afghanistan, trying to get out of the country. The names and nationalities of the hijackers are still unknown. With the release, more than 150 haggard passengers, kept on board for eight days, were freed unharmed. They flew to New Delhi, for family reunions, both wrenching and joyous.\n",
      "[32, 24362, 20, 48, 1280, 6227, 2352, 282, 18, 947, 20, 139, 3788, 3211, 11733, 25, 837, 9, 394, 20, 107, 24646, 308, 40, 18, 2212, 25, 1805, 19, 619, 22, 133, 78, 20, 18, 234, 9, 32, 1931, 21, 27321, 20, 18, 24362, 41, 194, 4027, 9, 473, 18, 947, 19, 70, 100, 4076, 10118, 299, 11992, 3372, 19, 1340, 31, 1036, 28, 869, 307, 19, 55, 8494, 28510, 9, 200, 5415, 22, 158, 6849, 19, 28, 273, 15459, 23, 19, 207, 17, 29741, 21, 30584, 9, 4145, 83, 8186, 3158, 10849, 7416, 83, 3158, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "98\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "98\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check for a observation with less than MAX_LEN tokens\n",
    "for i in df.index:\n",
    "    if(np.count_nonzero(df.loc[i, \"input_ids\"]) < 128):\n",
    "        print(\"Index:\", i)\n",
    "        print(df.loc[i, \"Text\"])\n",
    "        print(df.loc[i, \"input_ids\"])\n",
    "        print(np.count_nonzero(df.loc[i, \"input_ids\"]))\n",
    "        print(df.loc[i, \"attention_masks\"])\n",
    "        print(np.count_nonzero(df.loc[i, \"attention_masks\"]))\n",
    "        print(df.loc[i, \"segment_masks\"])\n",
    "        print(np.count_nonzero(df.loc[i, \"segment_masks\"]))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 831,
     "status": "ok",
     "timestamp": 1574023780270,
     "user": {
      "displayName": "Carlos Sancini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBK_a0VL329YfM0B72acZH97KLpfXxCOtGUCi9s=s64",
      "userId": "02726390835148099400"
     },
     "user_tz": 180
    },
    "id": "xF6iYg5F5E9G",
    "outputId": "8dff47c7-418f-46a9-c519-37165533d078"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>World</th>\n",
       "      <th>Washington</th>\n",
       "      <th>New_York_and_Region</th>\n",
       "      <th>Front_Page</th>\n",
       "      <th>Business</th>\n",
       "      <th>US</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Obituaries</th>\n",
       "      <th>Health</th>\n",
       "      <th>Education</th>\n",
       "      <th>Science</th>\n",
       "      <th>Technology</th>\n",
       "      <th>tokens</th>\n",
       "      <th>input_ids_full</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_masks</th>\n",
       "      <th>segment_masks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1215492</th>\n",
       "      <td>The Yankees called their temp agency -- Class ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[▁The, ▁Yankees, ▁called, ▁their, ▁temp, ▁agen...</td>\n",
       "      <td>[32, 6445, 271, 58, 16080, 1100, 17, 13, 13, 5...</td>\n",
       "      <td>[32, 6445, 271, 58, 16080, 1100, 17, 13, 13, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194582</th>\n",
       "      <td>To the Editor:\\nAs a psychiatrist, I am appall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[▁To, ▁the, ▁Editor, :, ▁As, ▁a, ▁psychiatrist...</td>\n",
       "      <td>[324, 18, 10955, 60, 228, 24, 18437, 19, 35, 5...</td>\n",
       "      <td>[324, 18, 10955, 60, 228, 24, 18437, 19, 35, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233574</th>\n",
       "      <td>In the Olympics, there is the quaint notion th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[▁In, ▁the, ▁Olympics, ,, ▁there, ▁is, ▁the, ▁...</td>\n",
       "      <td>[67, 18, 2807, 19, 105, 27, 18, 28657, 7097, 2...</td>\n",
       "      <td>[67, 18, 2807, 19, 105, 27, 18, 28657, 7097, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252507</th>\n",
       "      <td>DEAR DIARY:\\nOutside Our Lady of Mercy Medical...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[▁D, EAR, ▁DI, ARY, :, ▁Outside, ▁Our, ▁Lady, ...</td>\n",
       "      <td>[347, 15026, 17711, 25700, 60, 12468, 1146, 51...</td>\n",
       "      <td>[347, 15026, 17711, 25700, 60, 12468, 1146, 51...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166829</th>\n",
       "      <td>Don Martin, the Mad magazine cartoonist with a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[▁Don, ▁Martin, ,, ▁the, ▁Mad, ▁magazine, ▁car...</td>\n",
       "      <td>[1609, 1868, 19, 18, 5171, 2140, 28682, 33, 24...</td>\n",
       "      <td>[1609, 1868, 19, 18, 5171, 2140, 28682, 33, 24...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Text  World  Washington  \\\n",
       "Id                                                                              \n",
       "1215492  The Yankees called their temp agency -- Class ...      0           0   \n",
       "1194582  To the Editor:\\nAs a psychiatrist, I am appall...      0           0   \n",
       "1233574  In the Olympics, there is the quaint notion th...      0           0   \n",
       "1252507  DEAR DIARY:\\nOutside Our Lady of Mercy Medical...      0           0   \n",
       "1166829  Don Martin, the Mad magazine cartoonist with a...      0           0   \n",
       "\n",
       "         New_York_and_Region  Front_Page  Business  US  Sports  Obituaries  \\\n",
       "Id                                                                           \n",
       "1215492                    0           0         0   0       1           0   \n",
       "1194582                    0           0         0   0       0           0   \n",
       "1233574                    0           0         0   0       1           0   \n",
       "1252507                    1           0         0   0       0           0   \n",
       "1166829                    0           0         0   0       0           1   \n",
       "\n",
       "         Health  Education  Science  Technology  \\\n",
       "Id                                                \n",
       "1215492       0          0        0           0   \n",
       "1194582       0          0        1           0   \n",
       "1233574       0          0        0           0   \n",
       "1252507       0          0        0           0   \n",
       "1166829       0          0        0           0   \n",
       "\n",
       "                                                    tokens  \\\n",
       "Id                                                           \n",
       "1215492  [▁The, ▁Yankees, ▁called, ▁their, ▁temp, ▁agen...   \n",
       "1194582  [▁To, ▁the, ▁Editor, :, ▁As, ▁a, ▁psychiatrist...   \n",
       "1233574  [▁In, ▁the, ▁Olympics, ,, ▁there, ▁is, ▁the, ▁...   \n",
       "1252507  [▁D, EAR, ▁DI, ARY, :, ▁Outside, ▁Our, ▁Lady, ...   \n",
       "1166829  [▁Don, ▁Martin, ,, ▁the, ▁Mad, ▁magazine, ▁car...   \n",
       "\n",
       "                                            input_ids_full  \\\n",
       "Id                                                           \n",
       "1215492  [32, 6445, 271, 58, 16080, 1100, 17, 13, 13, 5...   \n",
       "1194582  [324, 18, 10955, 60, 228, 24, 18437, 19, 35, 5...   \n",
       "1233574  [67, 18, 2807, 19, 105, 27, 18, 28657, 7097, 2...   \n",
       "1252507  [347, 15026, 17711, 25700, 60, 12468, 1146, 51...   \n",
       "1166829  [1609, 1868, 19, 18, 5171, 2140, 28682, 33, 24...   \n",
       "\n",
       "                                                 input_ids  \\\n",
       "Id                                                           \n",
       "1215492  [32, 6445, 271, 58, 16080, 1100, 17, 13, 13, 5...   \n",
       "1194582  [324, 18, 10955, 60, 228, 24, 18437, 19, 35, 5...   \n",
       "1233574  [67, 18, 2807, 19, 105, 27, 18, 28657, 7097, 2...   \n",
       "1252507  [347, 15026, 17711, 25700, 60, 12468, 1146, 51...   \n",
       "1166829  [1609, 1868, 19, 18, 5171, 2140, 28682, 33, 24...   \n",
       "\n",
       "                                           attention_masks  \\\n",
       "Id                                                           \n",
       "1215492  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1194582  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1233574  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1252507  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1166829  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                             segment_masks  \n",
       "Id                                                          \n",
       "1215492  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1194582  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1233574  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1252507  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1166829  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38145,
     "status": "error",
     "timestamp": 1574073994493,
     "user": {
      "displayName": "Carlos Sancini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBK_a0VL329YfM0B72acZH97KLpfXxCOtGUCi9s=s64",
      "userId": "02726390835148099400"
     },
     "user_tz": 180
    },
    "id": "a9y5n_oickMe",
    "outputId": "20df5fa4-3fa9-4252-c002-3e55c39357d8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MODEL_PATH = \"../xlnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6F9u8iDBLBhH"
   },
   "outputs": [],
   "source": [
    "xlnet_ds_prepared = MODEL_PATH + \"/xlnet_prepared_ds_parquet.gzip\"\n",
    "df.to_parquet(xlnet_ds_prepared, compression='gzip')\n",
    "df = pd.read_parquet(xlnet_ds_prepared)\n",
    "#df = df.sample(50000, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dvid14fald_t"
   },
   "source": [
    "#### Split training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 664,
     "status": "ok",
     "timestamp": 1574074234569,
     "user": {
      "displayName": "Carlos Sancini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBK_a0VL329YfM0B72acZH97KLpfXxCOtGUCi9s=s64",
      "userId": "02726390835148099400"
     },
     "user_tz": 180
    },
    "id": "VP0l4vBo_QiL",
    "outputId": "23636e78-d509-4a68-e594-fc9a5fb85ebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25716, 18) (6430, 18)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state = SEED)\n",
    "\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vcWkqqj1zZmZ"
   },
   "source": [
    "#### Put data into data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pqqlXHl2GmAM"
   },
   "outputs": [],
   "source": [
    "tt_train_input_ids = torch.tensor(train_df[\"input_ids\"].tolist())\n",
    "tt_test_input_ids = torch.tensor(test_df[\"input_ids\"].tolist())\n",
    "\n",
    "tt_train_attention_masks = torch.tensor(train_df[\"attention_masks\"].tolist())\n",
    "tt_test_attention_masks = torch.tensor(test_df[\"attention_masks\"].tolist())\n",
    "\n",
    "tt_train_segment_masks = torch.tensor(train_df[\"segment_masks\"].tolist())\n",
    "tt_test_segment_masks = torch.tensor(test_df[\"segment_masks\"].tolist())\n",
    "\n",
    "label_columns = [\n",
    "  'World',\n",
    "  'Washington',\n",
    "  'New_York_and_Region',\n",
    "  'Front_Page',\n",
    "  'Business',\n",
    "  'US',\n",
    "  'Sports',\n",
    "  'Obituaries',\n",
    "  'Health',\n",
    "  'Education',\n",
    "  'Science',\n",
    "  'Technology']\n",
    "\n",
    "tt_train_labels = torch.tensor(train_df[label_columns].values.astype(np.float))\n",
    "tt_test_labels = torch.tensor(test_df[label_columns].values.astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zIePNKLWzh6N"
   },
   "outputs": [],
   "source": [
    "# training batch size\n",
    "batch_num = 32\n",
    "\n",
    "train_data = TensorDataset(\n",
    "    tt_train_input_ids, \n",
    "    tt_train_attention_masks, \n",
    "    tt_train_segment_masks, \n",
    "    tt_train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, sampler=train_sampler, batch_size=batch_num,drop_last=True)\n",
    "\n",
    "valid_data = TensorDataset(\n",
    "    tt_test_input_ids, \n",
    "    tt_test_attention_masks, \n",
    "    tt_test_segment_masks, \n",
    "    tt_test_labels)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=batch_num, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ub-NPcm_vMX-"
   },
   "source": [
    "#### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ogJYLS4Q67gl"
   },
   "outputs": [],
   "source": [
    "from transformers import XLNetPreTrainedModel\n",
    "from torch.nn import BCEWithLogitsLoss, Identity\n",
    "\n",
    "\"\"\"Copied from transformers package (modeling_utils.py) for dependencies\n",
    "  resolution. \"\"\"\n",
    "class SequenceSummary(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(SequenceSummary, self).__init__()\n",
    "\n",
    "        self.summary_type = config.summary_type if hasattr(config, 'summary_use_proj') else 'last'\n",
    "        if self.summary_type == 'attn':\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.summary = Identity()\n",
    "        if hasattr(config, 'summary_use_proj') and config.summary_use_proj:\n",
    "            if hasattr(config, 'summary_proj_to_labels') and config.summary_proj_to_labels and config.num_labels > 0:\n",
    "                num_classes = config.num_labels\n",
    "            else:\n",
    "                num_classes = config.hidden_size\n",
    "            self.summary = torch.nn.Linear(config.hidden_size, num_classes)\n",
    "\n",
    "        self.activation = Identity()\n",
    "        if hasattr(config, 'summary_activation') and config.summary_activation == 'tanh':\n",
    "            self.activation = torch.nn.Tanh()\n",
    "\n",
    "        self.first_dropout = Identity()\n",
    "        if hasattr(config, 'summary_first_dropout') and config.summary_first_dropout > 0:\n",
    "            self.first_dropout = torch.nn.Dropout(config.summary_first_dropout)\n",
    "\n",
    "        self.last_dropout = Identity()\n",
    "        if hasattr(config, 'summary_last_dropout') and config.summary_last_dropout > 0:\n",
    "            self.last_dropout = torch.nn.Dropout(config.summary_last_dropout)\n",
    "\n",
    "    def forward(self, hidden_states, cls_index=None):\n",
    "        \"\"\" hidden_states: float Tensor in shape [bsz, ..., seq_len, hidden_size], the hidden-states of the last layer.\n",
    "            cls_index: [optional] position of the classification token if summary_type == 'cls_index',\n",
    "                shape (bsz,) or more generally (bsz, ...) where ... are optional leading dimensions of hidden_states.\n",
    "                if summary_type == 'cls_index' and cls_index is None:\n",
    "                    we take the last token of the sequence as classification token\n",
    "        \"\"\"\n",
    "        if self.summary_type == 'last':\n",
    "            output = hidden_states[:, -1]\n",
    "        elif self.summary_type == 'first':\n",
    "            output = hidden_states[:, 0]\n",
    "        elif self.summary_type == 'mean':\n",
    "            output = hidden_states.mean(dim=1)\n",
    "        elif self.summary_type == 'cls_index':\n",
    "            if cls_index is None:\n",
    "                cls_index = torch.full_like(hidden_states[..., :1, :], hidden_states.shape[-2]-1, dtype=torch.long)\n",
    "            else:\n",
    "                cls_index = cls_index.unsqueeze(-1).unsqueeze(-1)\n",
    "                cls_index = cls_index.expand((-1,) * (cls_index.dim()-1) + (hidden_states.size(-1),))\n",
    "            # shape of cls_index: (bsz, XX, 1, hidden_size) where XX are optional leading dim of hidden_states\n",
    "            output = hidden_states.gather(-2, cls_index).squeeze(-2) # shape (bsz, XX, hidden_size)\n",
    "        elif self.summary_type == 'attn':\n",
    "            raise NotImplementedError\n",
    "\n",
    "        output = self.first_dropout(output)\n",
    "        output = self.summary(output)\n",
    "        output = self.activation(output)\n",
    "        output = self.last_dropout(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pwimhw3SvQUk"
   },
   "outputs": [],
   "source": [
    "\"\"\"Alters the XLNetForSequenceClassification from HuggingFace to cater \n",
    "   for multiclass multilabel classification . \"\"\"\n",
    "class XLNetForMultilabelSequenceClassification(XLNetPreTrainedModel):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(XLNetForMultilabelSequenceClassification, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.transformer = XLNetModel(config)\n",
    "        self.sequence_summary = SequenceSummary(config)\n",
    "        self.logits_proj = torch.nn.Linear(config.d_model, config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, \n",
    "                input_ids, \n",
    "                attention_mask=None, \n",
    "                mems=None, \n",
    "                perm_mask=None, \n",
    "                target_mapping=None,\n",
    "                token_type_ids=None, \n",
    "                input_mask=None, \n",
    "                head_mask=None, \n",
    "                labels=None):\n",
    "      \n",
    "        transformer_outputs = self.transformer(input_ids,\n",
    "                                               attention_mask=attention_mask,\n",
    "                                               mems=mems,\n",
    "                                               perm_mask=perm_mask,\n",
    "                                               target_mapping=target_mapping,\n",
    "                                               token_type_ids=token_type_ids,\n",
    "                                               input_mask=input_mask,\n",
    "                                               head_mask=head_mask)\n",
    "        output = transformer_outputs[0]\n",
    "\n",
    "        output = self.sequence_summary(output)\n",
    "        logits = self.logits_proj(output)\n",
    "\n",
    "        outputs = (logits,) + transformer_outputs[1:]  # Keep mems, hidden states, attentions if there are in it\n",
    "\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                #  We multilabel multiclass\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # return (loss), logits, (mems), (hidden states), (attentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SyEyQKcLzlF3"
   },
   "source": [
    "#### Load XLNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 52772,
     "status": "ok",
     "timestamp": 1574074310944,
     "user": {
      "displayName": "Carlos Sancini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBK_a0VL329YfM0B72acZH97KLpfXxCOtGUCi9s=s64",
      "userId": "02726390835148099400"
     },
     "user_tz": 180
    },
    "id": "mrsgCnjPzq1P",
    "outputId": "4aae5924-2758-4b46-cb1b-cb0ff32e1f65"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForMultilabelSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForMultilabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForMultilabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForMultilabelSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLNetForMultilabelSequenceClassification(\n",
       "  (transformer): XLNetModel(\n",
       "    (word_embedding): Embedding(32000, 768)\n",
       "    (layer): ModuleList(\n",
       "      (0): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (sequence_summary): SequenceSummary(\n",
       "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "    (first_dropout): Identity()\n",
       "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (logits_proj): Linear(in_features=768, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XLNetForMultilabelSequenceClassification.from_pretrained(\n",
    "    'xlnet-base-cased', num_labels=len(label_columns))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3gUYvgvzwTn"
   },
   "outputs": [],
   "source": [
    "# Set epoch and grad max num\n",
    "epochs = 2\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1574024618231,
     "user": {
      "displayName": "Carlos Sancini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBK_a0VL329YfM0B72acZH97KLpfXxCOtGUCi9s=s64",
      "userId": "02726390835148099400"
     },
     "user_tz": 180
    },
    "id": "74tTvA4Iz1ED",
    "outputId": "e75945a9-069e-4233-8567-acdb50eeda10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    betas: (0.9, 0.999)\n",
       "    correct_bias: True\n",
       "    eps: 1e-06\n",
       "    lr: 3e-05\n",
       "    weight_decay: 0.0\n",
       "    weight_decay_rate: 0.01\n",
       "\n",
       "Parameter Group 1\n",
       "    betas: (0.9, 0.999)\n",
       "    correct_bias: True\n",
       "    eps: 1e-06\n",
       "    lr: 3e-05\n",
       "    weight_decay: 0.0\n",
       "    weight_decay_rate: 0.0\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine tune model all layer parameters\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "      'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "      'weight_decay_rate': 0.0}\n",
    "]\n",
    "    \n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FoP-2uA1vix"
   },
   "source": [
    "#### Fine-tuning the XLNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCvUimI91zEF"
   },
   "outputs": [],
   "source": [
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 727701,
     "status": "ok",
     "timestamp": 1574009397949,
     "user": {
      "displayName": "Carlos Sancini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBK_a0VL329YfM0B72acZH97KLpfXxCOtGUCi9s=s64",
      "userId": "02726390835148099400"
     },
     "user_tz": 180
    },
    "id": "MqDr9Vl111Hi",
    "outputId": "3a3a5e8f-f03d-4820-f7ea-67ba2932144e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 25716\n",
      "  Batch size = 32\n",
      "Train loss: 0.3191992768529116\n",
      "Saving the results for the epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 1/2 [23:07<23:07, 1387.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.31418117433064857\n",
      "Saving the results for the epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 2/2 [46:17<00:00, 1388.76s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"***** Running training *****\")\n",
    "print(\"  Num examples = %d\"%(len(tt_train_input_ids)))\n",
    "print(\"  Batch size = %d\"%(batch_num))\n",
    "\n",
    "model_save_name = MODEL_PATH + \"/pytorch_model.bin\"\n",
    "model_config_save_name = MODEL_PATH + \"/config.json\"\n",
    "model_report_save_name = MODEL_PATH + \"/multilabel_eval_results.txt\"\n",
    "\n",
    "def delete_existing(filename):\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)    \n",
    "\n",
    "for epoch in trange(epochs,desc=\"Epoch\"):\n",
    "    logger.info(f'Starting epoch {epoch}')\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        logger.info(f'Starting step {step}')\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_segs, b_labels = batch\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(\n",
    "            input_ids = b_input_ids, \n",
    "            token_type_ids = b_segs, \n",
    "            input_mask = b_input_mask,\n",
    "            labels= b_labels)\n",
    "        loss, logits = outputs[:2]\n",
    "        if n_gpu>1:\n",
    "            # When multi gpu, average it\n",
    "            loss = loss.mean()\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    print(\"Saving the results for the epoch\")\n",
    "    logger.info(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    logger.info(\"Saving the results for the epoch\")\n",
    "    \n",
    "    delete_existing(model_save_name)\n",
    "    torch.save(model.state_dict(), model_save_name)\n",
    "    delete_existing(model_config_save_name)\n",
    "    model.config.to_json_file(model_config_save_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../xlnet/pytorch_model.bin\n",
      "../xlnet/config.json\n"
     ]
    }
   ],
   "source": [
    "print(model_save_name)\n",
    "print(model_config_save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JZfxzT3cChl5"
   },
   "source": [
    "#### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "irtWQYI9Ckuj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../xlnet/spiece.model',)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_vocabulary(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GfezBjSkDxxv"
   },
   "source": [
    "#### Loading finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vzHLlBrcDvnF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLNetForMultilabelSequenceClassification(\n",
       "  (transformer): XLNetModel(\n",
       "    (word_embedding): Embedding(32000, 768)\n",
       "    (layer): ModuleList(\n",
       "      (0): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (sequence_summary): SequenceSummary(\n",
       "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "    (first_dropout): Identity()\n",
       "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (logits_proj): Linear(in_features=768, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XLNetForMultilabelSequenceClassification.from_pretrained(\n",
    "    MODEL_PATH, num_labels=len(label_columns))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w3iXL7gbCAIt"
   },
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FymaCDX6-5DW"
   },
   "outputs": [],
   "source": [
    "root_folder = '../xlnet'\n",
    "\n",
    "def load_model(folder=MODEL_PATH):\n",
    "    model = XLNetForMultilabelSequenceClassification.from_pretrained(MODEL_PATH, num_labels=len(label_columns))\n",
    "    \n",
    "    if n_gpu != 0:\n",
    "        model.cuda()\n",
    "      \n",
    "    return model\n",
    "\n",
    "def save_object(filename, obj, folder=root_folder):\n",
    "    obj_file = os.path.join(folder, filename)\n",
    "\n",
    "    if os.path.exists(obj_file):\n",
    "        os.remove(obj_file)\n",
    "\n",
    "    with open(obj_file, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_object(filename, folder=root_folder):\n",
    "    object_file = os.path.join(folder, filename)\n",
    "\n",
    "    with open(object_file, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def calculate_confusion_matrix(data_loader, model, batch_size):\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(data_loader):\n",
    "            # add batch to gpu\n",
    "            if n_gpu != 0:\n",
    "                batch = tuple(t.to('cuda') for t in batch)\n",
    "            \n",
    "            logger.info(f'Step {step}')\n",
    "            #import pdb; pdb.set_trace()\n",
    "            b_input_ids, b_input_masks, b_segment_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            #raw_outputs = model(b_input_ids, b_segment_ids, b_input_masks)\n",
    "            raw_outputs = model(input_ids = b_input_ids, token_type_ids = b_segment_ids, input_mask = b_input_masks)\n",
    "            predictions.append((torch.sigmoid(raw_outputs[0]) > .5).cpu().numpy().astype(int))\n",
    "            true_labels.append(b_labels.cpu().numpy().astype(int))\n",
    "\n",
    "        true_labels = np.vstack(true_labels)[0:(batch_size * len(predictions)),]\n",
    "        predictions = np.vstack(predictions)\n",
    "\n",
    "        return (multilabel_confusion_matrix(true_labels, predictions),\n",
    "                true_labels,\n",
    "                predictions)\n",
    "\n",
    "def calculate_predictions(data_loader, model, batch_size):\n",
    "    if n_gpu != 0:\n",
    "        model.cuda()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()\n",
    "    result = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(data_loader):\n",
    "            logger.info(f'Step {step}')\n",
    "            \n",
    "            # add batch to gpu\n",
    "            if n_gpu != 0:\n",
    "                batch = tuple(t.to('cuda') for t in batch)\n",
    "                \n",
    "            b_input_ids, b_input_masks, b_segment_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            raw_outputs = model(b_input_ids, b_segment_ids, b_input_masks)\n",
    "            predictions = torch.sigmoid(raw_outputs[2]).cpu()\n",
    "            predictions = predictions.numpy()\n",
    "            result = predictions if result is None else np.append(result, predictions, axis=0)\n",
    "            \n",
    "        return result\n",
    "\n",
    "def get_label_columns(data_frame):\n",
    "    skip_columns =  { 'Id', 'Text', 'input_ids', 'attention_masks', 'segment_masks', 'input_ids_full', 'tokens' }\n",
    "    return [c for c in data_frame.columns if c not in skip_columns and '_Pred' not in c]\n",
    "\n",
    "def add_predictions(data_frame, features, model, batch_size):\n",
    "    logits = calculate_predictions(features, model, batch_size)\n",
    "    predictions = (logits > .5).astype(int)\n",
    "    \n",
    "    for i, column_name in enumerate(get_label_columns(data_frame)):\n",
    "        data_frame[f'{column_name}_Pred'] = predictions[:, i]\n",
    "\n",
    "def add_predictions_to_dataframe(data_frame, predictions):\n",
    "    for i, column_name in enumerate(get_label_columns(data_frame)):\n",
    "        data_frame[f'{column_name}_Pred'] = predictions[:, i]\n",
    "        \n",
    "class ModelResult:\n",
    "    def __init__(self, data_frame, features, model, batch_size):\n",
    "        confusion_matrix, labels, predictions = calculate_confusion_matrix(features, model, batch_size)\n",
    "        self.confusion_matrix = confusion_matrix\n",
    "        self.labels = labels\n",
    "        self.predictions = predictions\n",
    "        self.label_columns = get_label_columns(data_frame)\n",
    "        \n",
    "    def save(self, filename):\n",
    "        save_object(filename, self)\n",
    "        \n",
    "    def get_classification_report(self, output_dictionary):\n",
    "        return classification_report(self.labels, self.predictions, \n",
    "                                     target_names=self.label_columns, \n",
    "                                     output_dict=output_dictionary)\n",
    "        \n",
    "    def get_results_dataframe(self):\n",
    "        report_dict = self.get_classification_report(True)\n",
    "        label_columns = list(self.label_columns)\n",
    "        label_columns.append('weighted avg')\n",
    "        classification_results = pd.DataFrame({'Label':label_columns})\n",
    "        classification_results['Precision'] = [report_dict[c]['precision'] for c in label_columns]\n",
    "        classification_results['Recall'] = [report_dict[c]['recall'] for c in label_columns]\n",
    "        classification_results['F1-Score'] = [report_dict[c]['f1-score'] for c in label_columns]\n",
    "        classification_results['Support'] = [report_dict[c]['support'] for c in label_columns]\n",
    "        classification_results.loc[classification_results['Label'] == 'weighted avg', 'Label'] = 'Weighted Average'\n",
    "        \n",
    "        return classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = ModelResult(test_df, valid_dataloader, model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.save('xlnet_result_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = load_object('xlnet_result_test.pkl')\n",
    "model_results.label_columns = get_label_columns(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-9b913d7fef8b>:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[f'{column_name}_Pred'] = predictions[:, i]\n"
     ]
    }
   ],
   "source": [
    "add_predictions_to_dataframe(test_df, model_results.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6430, 30)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df[get_label_columns(test_df)].sum(1).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New_York_and_Region</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Front_Page</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sports</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Obituaries</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Health</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Education</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Science</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Technology</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Weighted Average</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Label  Precision  Recall  F1-Score  Support\n",
       "0                 World        0.0     0.0       0.0      886\n",
       "1            Washington        0.0     0.0       0.0      742\n",
       "2   New_York_and_Region        0.0     0.0       0.0     1827\n",
       "3            Front_Page        0.0     0.0       0.0      286\n",
       "4              Business        0.0     0.0       0.0      859\n",
       "5                    US        0.0     0.0       0.0     1965\n",
       "6                Sports        0.0     0.0       0.0     1694\n",
       "7            Obituaries        0.0     0.0       0.0      271\n",
       "8                Health        0.0     0.0       0.0      302\n",
       "9             Education        0.0     0.0       0.0       78\n",
       "10              Science        0.0     0.0       0.0      192\n",
       "11           Technology        0.0     0.0       0.0      143\n",
       "12     Weighted Average        0.0     0.0       0.0     9245"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results.get_results_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Label'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_results.get_results_dataframe().plot.barh(x='Label', y='Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'x':((model_results.labels == model_results.predictions).astype(int).sum(1))}).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World</th>\n",
       "      <th>Washington</th>\n",
       "      <th>New_York_and_Region</th>\n",
       "      <th>Front_Page</th>\n",
       "      <th>Business</th>\n",
       "      <th>US</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Obituaries</th>\n",
       "      <th>Health</th>\n",
       "      <th>Education</th>\n",
       "      <th>Science</th>\n",
       "      <th>Technology</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1237618</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226236</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191961</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177939</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252037</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196576</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245333</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205239</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234701</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182954</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         World  Washington  New_York_and_Region  Front_Page  Business  US  \\\n",
       "Id                                                                          \n",
       "1237618      1           1                    0           0         0   0   \n",
       "1226236      0           0                    0           0         0   0   \n",
       "1191961      0           0                    0           0         1   0   \n",
       "1177939      0           0                    1           0         0   0   \n",
       "1252037      0           0                    1           0         0   1   \n",
       "1196576      0           0                    0           0         1   0   \n",
       "1245333      0           0                    1           0         0   1   \n",
       "1205239      0           0                    0           0         1   0   \n",
       "1234701      0           0                    1           0         0   0   \n",
       "1182954      0           0                    0           0         0   1   \n",
       "\n",
       "         Sports  Obituaries  Health  Education  Science  Technology  \n",
       "Id                                                                   \n",
       "1237618       0           0       0          0        0           0  \n",
       "1226236       1           0       0          0        0           0  \n",
       "1191961       0           0       0          0        0           0  \n",
       "1177939       0           0       0          0        0           0  \n",
       "1252037       0           0       0          0        0           0  \n",
       "1196576       0           0       0          0        0           0  \n",
       "1245333       0           0       0          0        0           0  \n",
       "1205239       0           0       0          0        0           0  \n",
       "1234701       0           0       0          0        0           0  \n",
       "1182954       1           0       0          0        0           0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[get_label_columns(test_df)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World_Pred</th>\n",
       "      <th>Washington_Pred</th>\n",
       "      <th>New_York_and_Region_Pred</th>\n",
       "      <th>Front_Page_Pred</th>\n",
       "      <th>Business_Pred</th>\n",
       "      <th>US_Pred</th>\n",
       "      <th>Sports_Pred</th>\n",
       "      <th>Obituaries_Pred</th>\n",
       "      <th>Health_Pred</th>\n",
       "      <th>Education_Pred</th>\n",
       "      <th>Science_Pred</th>\n",
       "      <th>Technology_Pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1237618</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226236</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191961</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177939</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252037</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196576</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245333</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205239</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234701</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182954</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         World_Pred  Washington_Pred  New_York_and_Region_Pred  \\\n",
       "Id                                                               \n",
       "1237618           0                0                         0   \n",
       "1226236           0                0                         0   \n",
       "1191961           0                0                         0   \n",
       "1177939           0                0                         0   \n",
       "1252037           0                0                         0   \n",
       "1196576           0                0                         0   \n",
       "1245333           0                0                         0   \n",
       "1205239           0                0                         0   \n",
       "1234701           0                0                         0   \n",
       "1182954           0                0                         0   \n",
       "\n",
       "         Front_Page_Pred  Business_Pred  US_Pred  Sports_Pred  \\\n",
       "Id                                                              \n",
       "1237618                0              0        0            0   \n",
       "1226236                0              0        0            0   \n",
       "1191961                0              0        0            0   \n",
       "1177939                0              0        0            0   \n",
       "1252037                0              0        0            0   \n",
       "1196576                0              0        0            0   \n",
       "1245333                0              0        0            0   \n",
       "1205239                0              0        0            0   \n",
       "1234701                0              0        0            0   \n",
       "1182954                0              0        0            0   \n",
       "\n",
       "         Obituaries_Pred  Health_Pred  Education_Pred  Science_Pred  \\\n",
       "Id                                                                    \n",
       "1237618                0            0               0             0   \n",
       "1226236                0            0               0             0   \n",
       "1191961                0            0               0             0   \n",
       "1177939                0            0               0             0   \n",
       "1252037                0            0               0             0   \n",
       "1196576                0            0               0             0   \n",
       "1245333                0            0               0             0   \n",
       "1205239                0            0               0             0   \n",
       "1234701                0            0               0             0   \n",
       "1182954                0            0               0             0   \n",
       "\n",
       "         Technology_Pred  \n",
       "Id                        \n",
       "1237618                0  \n",
       "1226236                0  \n",
       "1191961                0  \n",
       "1177939                0  \n",
       "1252037                0  \n",
       "1196576                0  \n",
       "1245333                0  \n",
       "1205239                0  \n",
       "1234701                0  \n",
       "1182954                0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[[f'{c}_Pred' for c in get_label_columns(test_df)]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OUewusx3EKeY"
   },
   "outputs": [],
   "source": [
    "# Softtmax accuracy\n",
    "#def accuracy(out, labels):\n",
    "#    outputs = np.argmax(out, axis=1)\n",
    "#    return np.sum(outputs == labels)\n",
    "\n",
    "# Multilabel accuracy\n",
    "def accuracy(y_pred, y_true, thresh=0.5):\n",
    "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
    "    return np.mean(((y_pred > thresh) == y_true), axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zl1XtVnFiWL0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "  Num examples =6430\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "valid_dataloader = DataLoader(valid_data, batch_size=batch_num, drop_last=False, shuffle=False)\n",
    "\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "all_logits = None\n",
    "all_labels = None\n",
    "\n",
    "print(\"***** Running evaluation *****\")\n",
    "print(\"  Num examples ={}\".format(len(tt_test_input_ids)))\n",
    "print(\"  Batch size = {}\".format(batch_num))\n",
    "\n",
    "for step, batch in enumerate(valid_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_segs,b_labels = batch\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids = b_input_ids,\n",
    "            token_type_ids = b_segs, \n",
    "            input_mask = b_input_mask)\n",
    "        tmp_eval_loss, logits = outputs[:2]\n",
    "        logits = outputs[0]\n",
    "    \n",
    "    # Get textclassification predict result\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    tmp_eval_accuracy = accuracy(logits, label_ids)\n",
    "    \n",
    "    # Save predict and real label reuslt for analyze\n",
    "    if all_logits is None:\n",
    "        all_logits = logits\n",
    "    else:\n",
    "        all_logits = np.concatenate((all_logits, logits), axis=0)\n",
    "        \n",
    "    if all_labels is None:\n",
    "        all_labels = label_ids\n",
    "    else:    \n",
    "        all_labels = np.concatenate((all_labels, label_ids), axis=0)\n",
    "\n",
    "    eval_loss += tmp_eval_loss.mean().item()\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "   \n",
    "    nb_eval_steps += 1\n",
    "\n",
    "\n",
    "    \n",
    "eval_loss = eval_loss / nb_eval_steps\n",
    "eval_accuracy = eval_accuracy / len(tt_test_input_ids)\n",
    "\n",
    "#     ROC-AUC calcualation\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(label_columns)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(all_labels[:, i], all_logits[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(all_labels.ravel(), all_logits.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "result = {'eval_loss': eval_loss,\n",
    "          'eval_accuracy': eval_accuracy,\n",
    "          'roc_auc': roc_auc}\n",
    "\n",
    "with open(model_report_save_name, \"w\") as writer:\n",
    "    logger.info(\"***** Eval results *****\")\n",
    "    for key in sorted(result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "XLNet Multilabel NYT.ipynb",
   "provenance": [
    {
     "file_id": "1q3FAA-0F0G2e6qKhQ_navKJ3vcc2A9W1",
     "timestamp": 1573322451215
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
