{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "Sz5dMqVoLWQA",
    "outputId": "8ae43beb-a0b1-4d9c-983e-91f00c2e11a5"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "from transformers.modeling_bert import BertEmbeddings, BertLayerNorm, BertModel, BertPreTrainedModel, gelu\n",
    "from transformers import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    filename='roberta.log')\n",
    "logger = logging.getLogger('roberta.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FN0GUySc2zxf",
    "outputId": "76915fd6-da91-4953-e73c-1c98331149fd"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "if n_gpu != 0:\n",
    "    torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions to load and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SgJMUdJuCavo"
   },
   "outputs": [],
   "source": [
    "root_folder = '../bert'\n",
    "\n",
    "def save_model(model, model_filename, folder=root_folder):\n",
    "    ''' Save a pytorch model '''\n",
    "    model_file = os.path.join(folder, model_filename)\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        os.remove(model_file)\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "\n",
    "def load_model(model_filename, folder=root_folder):\n",
    "    ''' Load a pytorch model '''\n",
    "    model_file = os.path.join(folder, model_filename)\n",
    "    model = torch.load(model_filename)\n",
    "\n",
    "    if is_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    return model\n",
    "\n",
    "def remove_last_model(folder, model_filename, config_filename):\n",
    "    model_file = os.path.join(folder, model_filename)\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        os.remove(model_file)\n",
    "\n",
    "    config_file = os.path.join(folder, config_filename)\n",
    "\n",
    "    if os.path.exists(config_file):\n",
    "        os.remove(config_file)\n",
    "\n",
    "def file_exists(filename, folder=root_folder):\n",
    "    return os.path.exists(os.path.join(folder, filename))\n",
    "\n",
    "def save_object(filename, obj, folder=root_folder):\n",
    "    obj_file = os.path.join(folder, filename)\n",
    "\n",
    "    if os.path.exists(obj_file):\n",
    "        os.remove(obj_file)\n",
    "\n",
    "    with open(obj_file, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_object(filename, folder=root_folder):\n",
    "    object_file = os.path.join(folder, filename)\n",
    "\n",
    "    with open(object_file, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RoBERTa model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "z3fJqCe-puL0",
    "outputId": "492ad161-0504-44d3-b55e-f671bf69d91d"
   },
   "outputs": [],
   "source": [
    "model_class = RobertaModel\n",
    "tokenizer_class = RobertaTokenizer\n",
    "pretrained_weights = 'roberta-base'\n",
    "\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input (text) processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPPFrVtV996R"
   },
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, labels=None):\n",
    "        \"\"\"Constructs a InputExample.\"\"\"\n",
    "        self.text_a = text_a\n",
    "        self.labels = labels\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, label_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.label_ids = label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUKr9OU59-PE"
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, label_list, tokenizer, max_seq_length):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    features = []\n",
    "    count = 0\n",
    "\n",
    "    for example in examples:\n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "        tokens_b = None\n",
    "\n",
    "        if len(tokens_a) > max_seq_length - 2:\n",
    "            tokens_a = tokens_a[:(max_seq_length - 2)]\n",
    "\n",
    "        tokens = ['<s>'] + tokens_a + ['</s>']\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        \n",
    "        labels_ids = [float(label) for label in example.labels]\n",
    "        input_features = InputFeatures(input_ids, labels_ids)\n",
    "        features.append(input_features)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GZjUNwB3aRl"
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/nyt_full.parquet.gz')\n",
    "SEED = 17\n",
    "train, test = train_test_split(df, test_size=.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Uq4Q6rD_3lJV",
    "outputId": "0642bb9d-0978-47d7-b49e-f8579a6aeec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630802\n",
      "157701\n"
     ]
    }
   ],
   "source": [
    "print(len(train.Id))\n",
    "print(len(test.Id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZG2AW2naOOmT"
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 100\n",
    "label_columns = [c for c in train.columns if c not in ['Id', 'Text']]\n",
    "\n",
    "def get_labels(data, i):\n",
    "    return data.iloc[i][label_columns]\n",
    "\n",
    "def create_features(data, tokenizer, max_seq_length=MAX_SEQ_LENGTH):\n",
    "    logger.info('Processing labels')\n",
    "    label_list = data[label_columns].values.tolist()\n",
    "    logger.info('Processing examples')\n",
    "    examples = (InputExample(i, data.iloc[i].Text, labels=label_list[i]) for i in range(len(data)))\n",
    "    logger.info('Converting examples to features')\n",
    "\n",
    "    return convert_examples_to_features(examples, label_list, tokenizer, max_seq_length)\n",
    "\n",
    "def get_features(data, filename):\n",
    "    if file_exists(filename):\n",
    "        features = load_object(filename)\n",
    "    else:\n",
    "        tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "        features = create_features(data, tokenizer)\n",
    "        save_object(filename, features)\n",
    "\n",
    "    return features\n",
    "\n",
    "train_features = get_features(train, 'train_roberta_features.pkl')\n",
    "test_features = get_features(test, 'test_roberta_features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p6o0cIOz2nyf"
   },
   "outputs": [],
   "source": [
    "class RoBERTa(nn.Module):\n",
    "    \"\"\"BERT model for multiple label classification.\"\"\"\n",
    "    def __init__(self, num_labels, hidden_dropout_prob=.5):\n",
    "        super(RoBERTa, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.loss_fct = BCEWithLogitsLoss()\n",
    "\n",
    "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.dropout = torch.nn.Dropout(hidden_dropout_prob)\n",
    "        self.classifier = torch.nn.Linear(768, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, labels=None):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        hidden, pooled_output = self.roberta(input_ids)\n",
    "        x = self.dropout(pooled_output) # pooled_output\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        if labels is not None: \n",
    "            # Training the model     \n",
    "            return self.loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "        \n",
    "        else:\n",
    "            return hidden, pooled_output, logits\n",
    "            \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loader for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPqLF-ikWCAW"
   },
   "outputs": [],
   "source": [
    "batch_num = 40 #48\n",
    "\n",
    "def create_input_ids_tensor(data_features):\n",
    "    return torch.tensor([i.input_ids for i in data_features])\n",
    "\n",
    "def create_input_masks_tensor(data_features):\n",
    "    return torch.tensor([i.input_mask for i in data_features])\n",
    "\n",
    "def create_segment_ids_tensor(data_features):\n",
    "    return torch.tensor([i.segment_ids for i in data_features])\n",
    "\n",
    "def create_label_ids_tensor(data_features):\n",
    "    return torch.tensor([i.label_ids for i in data_features])\n",
    "\n",
    "def create_data_loader(data_features, batch_size=batch_num, drop_last=True, shuffle=True):\n",
    "    dataset = TensorDataset(\n",
    "      create_input_ids_tensor(data_features),\n",
    "      create_label_ids_tensor(data_features))\n",
    "    sampler = RandomSampler(dataset)\n",
    "\n",
    "    return DataLoader(dataset, sampler=sampler, batch_size=batch_size,drop_last=drop_last) if shuffle else DataLoader(dataset, batch_size=batch_size,drop_last=drop_last, shuffle=shuffle)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lGl6pNGteBoJ",
    "outputId": "5b99b946-7416-4405-8ea4-c43dcc09f2d7"
   },
   "outputs": [],
   "source": [
    "model = RoBERTa(len(train.columns) - 2)\n",
    "\n",
    "if n_gpu != 0:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9mLA1Oug7iL"
   },
   "outputs": [],
   "source": [
    "# Set epoch and grad max num\n",
    "epochs = 3\n",
    "max_grad_norm = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Yg9g2EWEhXWw",
    "outputId": "6001ea12-9b73-44a9-d45b-400aef0a6380"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoBERTa(\n",
       "  (loss_fct): BCEWithLogitsLoss()\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine tune model all layer parameters\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "      'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "      'weight_decay_rate': 0.0}\n",
    "]\n",
    "    \n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Y0goKuhf_K7"
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "def calculate_loss(model):\n",
    "    ''' Calculate the loss on the test set for the model '''\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        num_examples = 0\n",
    "\n",
    "        for steps, batch in enumerate(create_data_loader(test_features)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            batch_input_ids, batch_labels = batch\n",
    "            loss = model(batch_input_ids, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "            num_examples += batch_input_ids.size(0)\n",
    "\n",
    "        return total_loss / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "excBpkTgiHHo",
    "outputId": "97ddea63-4755-444d-ebdc-37eb98539980"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Main Training loop \n",
    "for i in trange(epochs,desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    num_examples, num_steps = 0, 0\n",
    "    \n",
    "    # Loop over the batches    \n",
    "    for step, batch in enumerate(create_data_loader(train_features)):\n",
    "        logger.info(f'Starting step {step}')\n",
    "        \n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_labels = batch\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(b_input_ids, b_labels)\n",
    "        loss = outputs\n",
    "        \n",
    "        if n_gpu>1:\n",
    "            # When multi gpu, average it\n",
    "            loss = loss.mean()\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        num_examples += b_input_ids.size(0)\n",
    "        num_steps += 1\n",
    "        \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    # print train loss per epoch\n",
    "    train_losses.append(tr_loss / num_examples)\n",
    "    test_losses.append(calculate_loss(model))\n",
    "    save_object('train_losses_roberta.pkl', train_losses)\n",
    "    save_object('test_losses_roberta.pkl', test_losses)\n",
    "    \n",
    "    # Display the results for the epoch\n",
    "    logger.info(f'Train loss: {train_losses[-1]}, test loss: {test_losses[-1]}') \n",
    "    print(f'Train loss: {train_losses[-1]}, test loss: {test_losses[-1]}')\n",
    "    \n",
    "    # Save the model\n",
    "    logger.info(f'Saving the model for the epoch {i}')\n",
    "    save_model(model, 'roberta.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'x':list(range(1, len(train_losses) + 1)), 'train':train_losses, 'dev':test_losses}).plot(x='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confusion_matrix(features, model, batch_size):\n",
    "    ''' Calculate the confusion matrix for the labels of the model '''\n",
    "    \n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(create_data_loader(features)):\n",
    "            # add batch to gpu\n",
    "            batch = tuple(t.to('cuda') for t in batch)\n",
    "            b_input_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            raw_outputs = model(b_input_ids)\n",
    "            predictions.append((torch.sigmoid(raw_outputs[2]) > .5).cpu().numpy().astype(int))\n",
    "            true_labels.append(b_labels.cpu().numpy().astype(int))\n",
    "\n",
    "        true_labels = np.vstack(true_labels)[0:(batch_size * len(predictions)),]\n",
    "        predictions = np.vstack(predictions)\n",
    "\n",
    "        return (multilabel_confusion_matrix(true_labels, predictions),\n",
    "                true_labels,\n",
    "                predictions)\n",
    "    \n",
    "def print_pct_correct(features, model):\n",
    "    tmp = calculate_confusion_matrix(features, model, 80)\n",
    "    print(f'Percentage correct {((tmp[1] == tmp[2]).astype(int).sum(1) == 12).sum() / tmp[1].shape[0]}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IYn6pn4A58nQ"
   },
   "outputs": [],
   "source": [
    "print_pct_correct(train_features, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_pct_correct(test_features, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename, folder=root_folder):\n",
    "    ''' Load the save model '''\n",
    "    \n",
    "    model = RoBERTa(len(train.columns) - 2)\n",
    "        \n",
    "    if n_gpu != 0:\n",
    "        state = torch.load(os.path.join(folder, filename))        \n",
    "        model.load_state_dict(state)        \n",
    "        model.cuda()\n",
    "    else:\n",
    "        state = torch.load(os.path.join(folder, filename), map_location=torch.device('cpu'))             \n",
    "        model.load_state_dict(state)\n",
    "      \n",
    "    return model\n",
    "\n",
    "def calculate_confusion_matrix(features, model, batch_size):\n",
    "    ''' Calculate the confusion matrix from a trained model '''\n",
    "    \n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(create_data_loader(features, batch_size, False, False)):\n",
    "            # add batch to gpu\n",
    "            if n_gpu != 0:\n",
    "                batch = tuple(t.to('cuda') for t in batch)\n",
    "            \n",
    "            logger.info(f'Step {step}')\n",
    "            b_input_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            raw_outputs = model(b_input_ids)\n",
    "            predictions.append((torch.sigmoid(raw_outputs[2]) > .5).cpu().numpy().astype(int))\n",
    "            true_labels.append(b_labels.cpu().numpy().astype(int))\n",
    "\n",
    "        true_labels = np.vstack(true_labels)[0:(batch_size * len(predictions)),]\n",
    "        predictions = np.vstack(predictions)\n",
    "\n",
    "        return (multilabel_confusion_matrix(true_labels, predictions),\n",
    "                true_labels,\n",
    "                predictions)\n",
    "\n",
    "def calculate_predictions(features, model, batch_size):\n",
    "    ''' Calculate the prediction from a trained model '''\n",
    "    \n",
    "    if n_gpu != 0:\n",
    "        model.cuda()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()\n",
    "    result = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(create_data_loader(features, batch_size, False, False)):\n",
    "            logger.info(f'Step {step}')\n",
    "            \n",
    "            # add batch to gpu\n",
    "            if n_gpu != 0:\n",
    "                batch = tuple(t.to('cuda') for t in batch)\n",
    "                \n",
    "            b_input_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            raw_outputs = model(b_input_ids)\n",
    "            predictions = torch.sigmoid(raw_outputs[2]).cpu()\n",
    "            predictions = predictions.numpy()\n",
    "            result = predictions if result is None else np.append(result, predictions, axis=0)\n",
    "            \n",
    "        return result\n",
    "\n",
    "def get_label_columns(data_frame):\n",
    "    ''' Return the columns with labels from the dataframe '''\n",
    "    return [c for c in data_frame.columns if c not in ('Id', 'Text') and '_Pred' not in c]\n",
    "\n",
    "def add_predictions(data_frame, features, model, batch_size):\n",
    "    ''' Calculate and add the predicted values to the dataframe '''\n",
    "    \n",
    "    logits = calculate_predictions(features, model, batch_size)\n",
    "    predictions = (logits > .5).astype(int)\n",
    "    \n",
    "    for i, column_name in enumerate(get_label_columns(data_frame)):\n",
    "        data_frame[f'{column_name}_Pred'] = predictions[:, i]\n",
    "\n",
    "def add_predictions_to_dataframe(data_frame, predictions):\n",
    "    ''' Add the model prediction to the dataframe '''\n",
    "    \n",
    "    for i, column_name in enumerate(get_label_columns(data_frame)):\n",
    "        data_frame[f'{column_name}_Pred'] = predictions[:, i]\n",
    "        \n",
    "class ModelResult:\n",
    "    ''' Helper class used to make prediction from a trained model '''\n",
    "    \n",
    "    def __init__(self, data_frame, features, model, batch_size):\n",
    "        confusion_matrix, labels, predictions = calculate_confusion_matrix(features, model, batch_size)\n",
    "        self.confusion_matrix = confusion_matrix\n",
    "        self.labels = labels\n",
    "        self.predictions = predictions\n",
    "        self.label_columns = get_label_columns(data_frame)\n",
    "        \n",
    "    def save(self, filename):\n",
    "        ''' Save the model results (this object) to disk '''\n",
    "        save_object(filename, self)\n",
    "        \n",
    "    def get_classification_report(self, output_dictionary):\n",
    "        ''' Return the classification report from the model predictions '''\n",
    "        \n",
    "        return classification_report(self.labels, self.predictions, \n",
    "                                     target_names=self.label_columns, \n",
    "                                     output_dict=output_dictionary)\n",
    "        \n",
    "    def get_results_dataframe(self):\n",
    "        ''' Create a summary dataframe with the results from the model '''\n",
    "        \n",
    "        report_dict = self.get_classification_report(True)\n",
    "        label_columns = list(self.label_columns)\n",
    "        label_columns.append('weighted avg')\n",
    "        classification_results = pd.DataFrame({'Label':label_columns})\n",
    "        classification_results['Precision'] = [report_dict[c]['precision'] for c in label_columns]\n",
    "        classification_results['Recall'] = [report_dict[c]['recall'] for c in label_columns]\n",
    "        classification_results['F1-Score'] = [report_dict[c]['f1-score'] for c in label_columns]\n",
    "        classification_results['Support'] = [report_dict[c]['support'] for c in label_columns]\n",
    "        classification_results.loc[classification_results['Label'] == 'weighted avg', 'Label'] = 'Weighted Average'\n",
    "        \n",
    "        return classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('roberta.pt', '../bert')\n",
    "model_results = ModelResult(test, test_features, model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.save('roberta_result_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = load_object('roberta_result_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marceloblinder/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "add_predictions_to_dataframe(test, model_results.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc077fbd750>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test[get_label_columns(test)].sum(1).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marceloblinder/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World</td>\n",
       "      <td>0.857715</td>\n",
       "      <td>0.886597</td>\n",
       "      <td>0.871917</td>\n",
       "      <td>24144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington</td>\n",
       "      <td>0.725615</td>\n",
       "      <td>0.716796</td>\n",
       "      <td>0.721178</td>\n",
       "      <td>9050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New_York_and_Region</td>\n",
       "      <td>0.935439</td>\n",
       "      <td>0.919620</td>\n",
       "      <td>0.927462</td>\n",
       "      <td>35718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Front_Page</td>\n",
       "      <td>0.928387</td>\n",
       "      <td>0.341871</td>\n",
       "      <td>0.499723</td>\n",
       "      <td>5271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business</td>\n",
       "      <td>0.973181</td>\n",
       "      <td>0.961920</td>\n",
       "      <td>0.967518</td>\n",
       "      <td>43382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US</td>\n",
       "      <td>0.792056</td>\n",
       "      <td>0.790217</td>\n",
       "      <td>0.791135</td>\n",
       "      <td>34040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sports</td>\n",
       "      <td>0.985067</td>\n",
       "      <td>0.973380</td>\n",
       "      <td>0.979189</td>\n",
       "      <td>33546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Obituaries</td>\n",
       "      <td>0.983621</td>\n",
       "      <td>0.990818</td>\n",
       "      <td>0.987206</td>\n",
       "      <td>6970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Health</td>\n",
       "      <td>0.778014</td>\n",
       "      <td>0.735203</td>\n",
       "      <td>0.756003</td>\n",
       "      <td>7451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Education</td>\n",
       "      <td>0.727915</td>\n",
       "      <td>0.590258</td>\n",
       "      <td>0.651899</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Science</td>\n",
       "      <td>0.793887</td>\n",
       "      <td>0.720996</td>\n",
       "      <td>0.755688</td>\n",
       "      <td>4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Technology</td>\n",
       "      <td>0.767640</td>\n",
       "      <td>0.702014</td>\n",
       "      <td>0.733362</td>\n",
       "      <td>2433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Weighted Average</td>\n",
       "      <td>0.899204</td>\n",
       "      <td>0.875554</td>\n",
       "      <td>0.883765</td>\n",
       "      <td>207616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Label  Precision    Recall  F1-Score  Support\n",
       "0                 World   0.857715  0.886597  0.871917    24144\n",
       "1            Washington   0.725615  0.716796  0.721178     9050\n",
       "2   New_York_and_Region   0.935439  0.919620  0.927462    35718\n",
       "3            Front_Page   0.928387  0.341871  0.499723     5271\n",
       "4              Business   0.973181  0.961920  0.967518    43382\n",
       "5                    US   0.792056  0.790217  0.791135    34040\n",
       "6                Sports   0.985067  0.973380  0.979189    33546\n",
       "7            Obituaries   0.983621  0.990818  0.987206     6970\n",
       "8                Health   0.778014  0.735203  0.756003     7451\n",
       "9             Education   0.727915  0.590258  0.651899     1396\n",
       "10              Science   0.793887  0.720996  0.755688     4215\n",
       "11           Technology   0.767640  0.702014  0.733362     2433\n",
       "12     Weighted Average   0.899204  0.875554  0.883765   207616"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results.get_results_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc0939a4f50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_results.get_results_dataframe().plot.barh(x='Label', y='Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc08e15a150>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'x':((model_results.labels == model_results.predictions).astype(int).sum(1))}).plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ns2V0n20FRwh"
   },
   "source": [
    "## Saving the model\n",
    "\n",
    "* [pytorch](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
    "\n",
    "* [Google Drive](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=D78AM1fFt2ty)\n",
    "\n",
    "## Bert\n",
    "\n",
    "* [Bert Tutorial (Hidden Layers)](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/)\n",
    "\n",
    "* [GIT Huggingface](https://github.com/huggingface/transformers/blob/master/transformers/modeling_bert.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TorchBert 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
