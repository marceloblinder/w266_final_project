{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "Sz5dMqVoLWQA",
    "outputId": "8ae43beb-a0b1-4d9c-983e-91f00c2e11a5"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "from transformers.modeling_bert import BertEmbeddings, BertLayerNorm, BertModel, BertPreTrainedModel, gelu\n",
    "from transformers import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    filename='bert_dpcnn.log')\n",
    "logger = logging.getLogger('bert_dpcnn.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FN0GUySc2zxf",
    "outputId": "76915fd6-da91-4953-e73c-1c98331149fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla K80'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions to load/save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SgJMUdJuCavo"
   },
   "outputs": [],
   "source": [
    "root_folder = '../bert'\n",
    "\n",
    "def save_model(model, model_filename, folder=root_folder):\n",
    "    ''' Save a pytorch model '''\n",
    "    model_file = os.path.join(folder, model_filename)\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        os.remove(model_file)\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "\n",
    "def load_model(model_filename, folder=root_folder):\n",
    "    ''' Load a pytorch model '''\n",
    "    model_file = os.path.join(folder, model_filename)\n",
    "    model = torch.load(model_filename)\n",
    "\n",
    "    if is_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    return model\n",
    "\n",
    "def remove_last_model(folder, model_filename, config_filename):\n",
    "    model_file = os.path.join(folder, model_filename)\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        os.remove(model_file)\n",
    "\n",
    "    config_file = os.path.join(folder, config_filename)\n",
    "\n",
    "    if os.path.exists(config_file):\n",
    "        os.remove(config_file)\n",
    "\n",
    "def file_exists(filename, folder=root_folder):\n",
    "    return os.path.exists(os.path.join(folder, filename))\n",
    "\n",
    "def save_object(filename, obj, folder=root_folder):\n",
    "    obj_file = os.path.join(folder, filename)\n",
    "\n",
    "    if os.path.exists(obj_file):\n",
    "        os.remove(obj_file)\n",
    "\n",
    "    with open(obj_file, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_object(filename, folder=root_folder):\n",
    "    object_file = os.path.join(folder, filename)\n",
    "\n",
    "    with open(object_file, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "z3fJqCe-puL0",
    "outputId": "492ad161-0504-44d3-b55e-f671bf69d91d"
   },
   "outputs": [],
   "source": [
    "model_class = BertModel\n",
    "tokenizer_class = BertTokenizer\n",
    "pretrained_weights = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input (text) processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPPFrVtV996R"
   },
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, labels=None):\n",
    "        \"\"\"Constructs a InputExample.\"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.labels = labels\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUKr9OU59-PE"
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, label_list, max_seq_length):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    features = []\n",
    "    count = 0\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "    for example in examples:\n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "\n",
    "        if len(tokens_a) > max_seq_length - 2:\n",
    "            tokens_a = tokens_a[:(max_seq_length - 2)]\n",
    "\n",
    "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
    "        segment_ids = [0] * len(tokens)\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "        \n",
    "        labels_ids = [float(label) for label in example.labels]\n",
    "        features.append(InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_ids=labels_ids))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GZjUNwB3aRl"
   },
   "outputs": [],
   "source": [
    "# Load the full dataset into a DataFrame\n",
    "df = pd.read_parquet('../data/nyt_full.parquet.gz')\n",
    "SEED = 17\n",
    "train, test = train_test_split(df, test_size=.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Uq4Q6rD_3lJV",
    "outputId": "0642bb9d-0978-47d7-b49e-f8579a6aeec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630802\n",
      "157701\n"
     ]
    }
   ],
   "source": [
    "print(len(train.Id))\n",
    "print(len(test.Id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZG2AW2naOOmT"
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 128\n",
    "label_columns = [c for c in train.columns if c not in ['Id', 'Text']]\n",
    "\n",
    "def get_labels(data, i):\n",
    "    return data.iloc[i][label_columns]\n",
    "\n",
    "def create_features(data, max_seq_length=MAX_SEQ_LENGTH):\n",
    "    ''' Create the features for the BERT model '''\n",
    "    \n",
    "    print('Processing labels')\n",
    "    #label_list = [get_labels(data, i) for i in range(len(data))]\n",
    "    label_list = data[label_columns].values.tolist()\n",
    "    print('Processing examples')\n",
    "    examples = [InputExample(i, data.iloc[i].Text, labels=label_list[i]) for i in range(len(data))]\n",
    "    print('Converting examples to features')\n",
    "\n",
    "    return convert_examples_to_features(examples, label_list, max_seq_length)\n",
    "\n",
    "def get_features(data, filename):\n",
    "    ''' Create the features to the model '''\n",
    "    \n",
    "    if file_exists(filename):\n",
    "        features = load_object(filename)\n",
    "    else:\n",
    "        features = create_features(data)\n",
    "        save_object(filename, features)\n",
    "\n",
    "    return features\n",
    "\n",
    "train_features = get_features(train, 'train_bert_features.pkl')\n",
    "test_features = get_features(test, 'test_bert_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4AjFtP_81D1"
   },
   "outputs": [],
   "source": [
    "class DPCNN(nn.Module):\n",
    "    ''' Class used to create the DPCNN '''\n",
    "    def __init__(self, num_labels, channel_size=250, width=768):\n",
    "        super(DPCNN, self).__init__()\n",
    "        self.conv_embedding = nn.Conv2d(1, channel_size, (3, width))\n",
    "        self.conv2 = nn.Conv2d(channel_size, channel_size, (3, 1))\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=(3,1), stride=2)\n",
    "        self.padding_conv = nn.ZeroPad2d((0, 0, 1, 1))\n",
    "        self.padding_pool = nn.ZeroPad2d((0, 0, 0, 1))\n",
    "        self.activation_function = nn.ReLU()\n",
    "        self.last_linear = nn.Linear(channel_size, num_labels)\n",
    "        self.channel_size = channel_size\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        # Expected 4-dimensional input for 4-dimensional weight 3 1 3 768, but got 2-dimensional input of size [32, 768] instead\n",
    "        batch_size, width, height = embeddings.shape\n",
    "\n",
    "        # First transform the BERT embeddings (batch_size, num_characters, 768),\n",
    "        # like (64, 80, 768)\n",
    "        # to a 4D tensor like [64, 1, 80, 768] (required by the Conv2d)\n",
    "        x = embeddings.view((batch_size, 1, width, height))\n",
    "\n",
    "        # Run the first convolution (embedding). The output is [64, 250, 78, 1] \n",
    "        x = self.conv_embedding(x)\n",
    "        #print(f'1 {x.shape}')        \n",
    "        #x = self.activation_function(x)\n",
    "        x_save = x\n",
    "\n",
    "        # Run the second convolution. The output is [64, 250, 76, 1]\n",
    "        x = self.conv2(x)\n",
    "        #print(f'2 {x.shape}')\n",
    "\n",
    "        # Add padding at starting and ending rows of the tensor. After that the\n",
    "        # shape will be [64, 250, 78, 1]\n",
    "        x = self.padding_conv(x)\n",
    "        #x = self.activation_function(x)\n",
    "\n",
    "        # Run another convolution. After that the shape will be [64, 250, 76, 1]\n",
    "        x = self.conv2(x)\n",
    "        x = self.padding_conv(x)\n",
    "        x = x + self.activation_function(x_save)\n",
    "        #print(f'3 {x.shape}')\n",
    "\n",
    "        # Go over the blocks\n",
    "        while x.shape[-2] >= 2:\n",
    "            #print(x.shape)\n",
    "            x = self.padding_pool(x)\n",
    "            #print(f'3.1 {x.shape}')\n",
    "\n",
    "            # Save the pool output to add that to the convolutions at the end\n",
    "            pooling_x = self.pooling(x) \n",
    "            #print(f'pooling {pooling_x.shape}')\n",
    "\n",
    "            # Perform the first convolution\n",
    "            x = self.padding_conv(pooling_x)\n",
    "            x = nn.functional.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            #print(f'4 {x.shape}')\n",
    "\n",
    "            # Perform the second convolution\n",
    "            x = self.padding_conv(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            #print(f'5 {x.shape}')\n",
    "\n",
    "            # Do the addition \n",
    "            x = x + pooling_x\n",
    "\n",
    "        x = x.view(batch_size, self.channel_size)\n",
    "        x = self.last_linear(x)\n",
    "         \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p6o0cIOz2nyf"
   },
   "outputs": [],
   "source": [
    "class BertFull(nn.Module):\n",
    "    \"\"\"BERT model for multiple label classification.\"\"\"\n",
    "    def __init__(self, num_labels, hidden_dropout_prob=.5):\n",
    "        super(BertFull, self).__init__()\n",
    "        num_labels = len(label_columns)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel.from_pretrained(pretrained_weights)\n",
    "        self.dropout = torch.nn.Dropout(hidden_dropout_prob)\n",
    "        self.dpcnn = DPCNN(num_labels)\n",
    "        self.classifier = torch.nn.Linear(num_labels, num_labels)\n",
    "        self.loss_fct = BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        hidden, pooled_output = self.bert(input_ids, token_type_ids, attention_mask)\n",
    "        x = self.dropout(hidden) # pooled_output\n",
    "        x = self.dpcnn(x)\n",
    "\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        if labels is not None: \n",
    "            # Training the model     \n",
    "            return self.loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "        \n",
    "        else:\n",
    "            return hidden, pooled_output, logits\n",
    "            \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loader for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPqLF-ikWCAW"
   },
   "outputs": [],
   "source": [
    "batch_num = 40 #48\n",
    "\n",
    "def create_input_ids_tensor(data_features):\n",
    "    return torch.tensor([i.input_ids for i in data_features])\n",
    "\n",
    "def create_input_masks_tensor(data_features):\n",
    "    return torch.tensor([i.input_mask for i in data_features])\n",
    "\n",
    "def create_segment_ids_tensor(data_features):\n",
    "    return torch.tensor([i.segment_ids for i in data_features])\n",
    "\n",
    "def create_label_ids_tensor(data_features):\n",
    "    return torch.tensor([i.label_ids for i in data_features])\n",
    "\n",
    "def create_data_loader(data_features, batch_size=batch_num, drop_last=True, shuffle=True):\n",
    "    dataset = TensorDataset(\n",
    "      create_input_ids_tensor(data_features),\n",
    "      create_input_masks_tensor(data_features),\n",
    "      create_segment_ids_tensor(data_features),\n",
    "      create_label_ids_tensor(data_features))\n",
    "    sampler = RandomSampler(dataset)\n",
    "\n",
    "    return DataLoader(dataset, sampler=sampler, batch_size=batch_size,drop_last=drop_last) if shuffle else DataLoader(dataset, batch_size=batch_size,drop_last=drop_last, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lGl6pNGteBoJ",
    "outputId": "5b99b946-7416-4405-8ea4-c43dcc09f2d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertFull(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (dpcnn): DPCNN(\n",
       "    (conv_embedding): Conv2d(1, 250, kernel_size=(3, 768), stride=(1, 1))\n",
       "    (conv2): Conv2d(250, 250, kernel_size=(3, 1), stride=(1, 1))\n",
       "    (pooling): MaxPool2d(kernel_size=(3, 1), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (padding_conv): ZeroPad2d(padding=(0, 0, 1, 1), value=0.0)\n",
       "    (padding_pool): ZeroPad2d(padding=(0, 0, 0, 1), value=0.0)\n",
       "    (activation_function): ReLU()\n",
       "    (last_linear): Linear(in_features=250, out_features=12, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=12, out_features=12, bias=True)\n",
       "  (loss_fct): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_weights = 'bert-base-uncased'\n",
    "model = BertFull(len(train.columns) - 2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9mLA1Oug7iL"
   },
   "outputs": [],
   "source": [
    "# Set epoch and grad max num\n",
    "epochs = 5\n",
    "max_grad_norm = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Yg9g2EWEhXWw",
    "outputId": "6001ea12-9b73-44a9-d45b-400aef0a6380"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertFull(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (dpcnn): DPCNN(\n",
       "    (conv_embedding): Conv2d(1, 250, kernel_size=(3, 768), stride=(1, 1))\n",
       "    (conv2): Conv2d(250, 250, kernel_size=(3, 1), stride=(1, 1))\n",
       "    (pooling): MaxPool2d(kernel_size=(3, 1), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (padding_conv): ZeroPad2d(padding=(0, 0, 1, 1), value=0.0)\n",
       "    (padding_pool): ZeroPad2d(padding=(0, 0, 0, 1), value=0.0)\n",
       "    (activation_function): ReLU()\n",
       "    (last_linear): Linear(in_features=250, out_features=12, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=12, out_features=12, bias=True)\n",
       "  (loss_fct): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine tune model all layer parameters\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "      'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "      'weight_decay_rate': 0.0}\n",
    "]\n",
    "    \n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Y0goKuhf_K7"
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "def calculate_loss(model):\n",
    "    ''' Calculate the loss on the test set for the model '''\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        num_examples = 0\n",
    "\n",
    "        for steps, batch in enumerate(create_data_loader(test_features)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            batch_input_ids, batch_input_masks, batch_segment_ids, batch_labels = batch\n",
    "            loss = model(batch_input_ids, batch_segment_ids, batch_input_masks, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "            num_examples += batch_input_ids.size(0)\n",
    "\n",
    "        return total_loss / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "excBpkTgiHHo",
    "outputId": "97ddea63-4755-444d-ebdc-37eb98539980"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.002227660102770323, test loss: 0.0019051865172392407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 1/5 [5:33:38<22:14:34, 20018.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0017125521630645814, test loss: 0.0018280143801473509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 2/5 [11:07:14<16:40:53, 20017.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0014645200805442104, test loss: 0.001907405155498954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 3/5 [16:40:59<11:07:19, 20019.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0012557968735171052, test loss: 0.0019276593542950277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 4/5 [22:14:46<5:33:42, 20022.09s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0010742939475757828, test loss: 0.0020544417143349533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [27:48:38<00:00, 20023.73s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Main Training loop \n",
    "for i in trange(epochs,desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    num_examples, num_steps = 0, 0\n",
    "    \n",
    "    # Loop over the batches    \n",
    "    for step, batch in enumerate(create_data_loader(train_features)):\n",
    "        logger.info(f'Starting step {step}')\n",
    "        \n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_masks, b_segment_ids, b_labels = batch\n",
    "        \n",
    "        # forward pass\n",
    "        outputs= model(b_input_ids, b_segment_ids, b_input_masks, b_labels)\n",
    "        loss = outputs\n",
    "        \n",
    "        if n_gpu>1:\n",
    "            # When multi gpu, average it\n",
    "            loss = loss.mean()\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        num_examples += b_input_ids.size(0)\n",
    "        num_steps += 1\n",
    "        \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    # print train loss per epoch\n",
    "    train_losses.append(tr_loss / num_examples)\n",
    "    test_losses.append(calculate_loss(model))\n",
    "    save_object('train_losses_bert_dpcnn.pkl', train_losses)\n",
    "    save_object('test_losses_bert_dpcnn.pkl', test_losses)\n",
    "    logger.info(f'Train loss: {train_losses[-1]}, test loss: {test_losses[-1]}') \n",
    "    print(f'Train loss: {train_losses[-1]}, test loss: {test_losses[-1]}')\n",
    "    logger.info(f'Saving the model for the epoch {i}')\n",
    "    save_model(model, 'bert_dpcnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f35d7026f90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'x':list(range(1, len(train_losses) + 1)), 'train':train_losses, 'dev':test_losses}).plot(x='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confusion_matrix(features, model, batch_size):\n",
    "    ''' Calculate the confusion matrix for the labels of the model '''\n",
    "    \n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(create_data_loader(features)):\n",
    "            # add batch to gpu\n",
    "            batch = tuple(t.to('cuda') for t in batch)\n",
    "            b_input_ids, b_input_masks, b_segment_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            raw_outputs = model(b_input_ids, b_segment_ids, b_input_masks)\n",
    "            predictions.append((torch.sigmoid(raw_outputs[2]) > .5).cpu().numpy().astype(int))\n",
    "            true_labels.append(b_labels.cpu().numpy().astype(int))\n",
    "\n",
    "        true_labels = np.vstack(true_labels)[0:(batch_size * len(predictions)),]\n",
    "        predictions = np.vstack(predictions)\n",
    "\n",
    "        return (multilabel_confusion_matrix(true_labels, predictions),\n",
    "                true_labels,\n",
    "                predictions)\n",
    "    \n",
    "def print_pct_correct(features, model):\n",
    "    tmp = calculate_confusion_matrix(features, model, 80)\n",
    "    print(f'Percentage correct {((tmp[1] == tmp[2]).astype(int).sum(1) == 12).sum() / tmp[1].shape[0]}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IYn6pn4A58nQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct 0.8911842105263158\n"
     ]
    }
   ],
   "source": [
    "print_pct_correct(train_features, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct 0.7612696600710299\n"
     ]
    }
   ],
   "source": [
    "print_pct_correct(test_features, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename, folder=root_folder):\n",
    "    ''' Load the save model '''\n",
    "    model = BertFull(len(train.columns) - 2)\n",
    "        \n",
    "    if n_gpu != 0:\n",
    "        state = torch.load(os.path.join(folder, filename))        \n",
    "        model.load_state_dict(state)        \n",
    "        model.cuda()\n",
    "    else:\n",
    "        state = torch.load(os.path.join(folder, filename), map_location=torch.device('cpu'))             \n",
    "        model.load_state_dict(state)\n",
    "      \n",
    "    return model\n",
    "\n",
    "def calculate_confusion_matrix(features, model, batch_size):\n",
    "    ''' Calculate the confusion matrix from a trained model '''\n",
    "    \n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(create_data_loader(features, batch_size, False, False)):\n",
    "            # add batch to gpu\n",
    "            if n_gpu != 0:\n",
    "                batch = tuple(t.to('cuda') for t in batch)\n",
    "            \n",
    "            logger.info(f'Step {step}')\n",
    "            b_input_ids, b_input_masks, b_segment_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            raw_outputs = model(b_input_ids, b_segment_ids, b_input_masks)\n",
    "            predictions.append((torch.sigmoid(raw_outputs[2]) > .5).cpu().numpy().astype(int))\n",
    "            true_labels.append(b_labels.cpu().numpy().astype(int))\n",
    "\n",
    "        true_labels = np.vstack(true_labels)[0:(batch_size * len(predictions)),]\n",
    "        predictions = np.vstack(predictions)\n",
    "\n",
    "        return (multilabel_confusion_matrix(true_labels, predictions),\n",
    "                true_labels,\n",
    "                predictions)\n",
    "\n",
    "def calculate_predictions(features, model, batch_size):\n",
    "    ''' Calculate the prediction from a trained model '''\n",
    "    \n",
    "    if n_gpu != 0:\n",
    "        model.cuda()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()\n",
    "    result = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(create_data_loader(features, batch_size, False, False)):\n",
    "            logger.info(f'Step {step}')\n",
    "            \n",
    "            # add batch to gpu\n",
    "            if n_gpu != 0:\n",
    "                batch = tuple(t.to('cuda') for t in batch)\n",
    "                \n",
    "            b_input_ids, b_input_masks, b_segment_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            raw_outputs = model(b_input_ids, b_segment_ids, b_input_masks)\n",
    "            predictions = torch.sigmoid(raw_outputs[2]).cpu()\n",
    "            predictions = predictions.numpy()\n",
    "            result = predictions if result is None else np.append(result, predictions, axis=0)\n",
    "            \n",
    "        return result\n",
    "\n",
    "def get_label_columns(data_frame):\n",
    "    ''' Return the columns with labels from the dataframe '''\n",
    "    return [c for c in data_frame.columns if c not in ('Id', 'Text') and '_Pred' not in c]\n",
    "\n",
    "def add_predictions(data_frame, features, model, batch_size):\n",
    "    ''' Calculate and add the predicted values to the dataframe '''\n",
    "    logits = calculate_predictions(features, model, batch_size)\n",
    "    predictions = (logits > .5).astype(int)\n",
    "    \n",
    "    for i, column_name in enumerate(get_label_columns(data_frame)):\n",
    "        data_frame[f'{column_name}_Pred'] = predictions[:, i]\n",
    "\n",
    "def add_predictions_to_dataframe(data_frame, predictions):\n",
    "    ''' Add the model prediction to the dataframe '''\n",
    "    \n",
    "    for i, column_name in enumerate(get_label_columns(data_frame)):\n",
    "        data_frame[f'{column_name}_Pred'] = predictions[:, i]\n",
    "        \n",
    "class ModelResult:\n",
    "    ''' Helper class used to make prediction from a trained model '''\n",
    "\n",
    "    def __init__(self, data_frame, features, model, batch_size):\n",
    "        confusion_matrix, labels, predictions = calculate_confusion_matrix(features, model, batch_size)\n",
    "        self.confusion_matrix = confusion_matrix\n",
    "        self.labels = labels\n",
    "        self.predictions = predictions\n",
    "        self.label_columns = get_label_columns(data_frame)\n",
    "        \n",
    "    def save(self, filename):\n",
    "        ''' Save the model results (this object) to disk '''\n",
    "        save_object(filename, self)\n",
    "        \n",
    "    def get_classification_report(self, output_dictionary):\n",
    "        ''' Return the classification report from the model predictions '''\n",
    "        \n",
    "        return classification_report(self.labels, self.predictions, \n",
    "                                     target_names=self.label_columns, \n",
    "                                     output_dict=output_dictionary)\n",
    "        \n",
    "    def get_results_dataframe(self):\n",
    "        ''' Create a summary dataframe with the results from the model '''\n",
    "        \n",
    "        report_dict = self.get_classification_report(True)\n",
    "        label_columns = list(self.label_columns)\n",
    "        label_columns.append('weighted avg')\n",
    "        classification_results = pd.DataFrame({'Label':label_columns})\n",
    "        classification_results['Precision'] = [report_dict[c]['precision'] for c in label_columns]\n",
    "        classification_results['Recall'] = [report_dict[c]['recall'] for c in label_columns]\n",
    "        classification_results['F1-Score'] = [report_dict[c]['f1-score'] for c in label_columns]\n",
    "        classification_results['Support'] = [report_dict[c]['support'] for c in label_columns]\n",
    "        classification_results.loc[classification_results['Label'] == 'weighted avg', 'Label'] = 'Weighted Average'\n",
    "        \n",
    "        return classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('bert_dpcnn.pt', '../bert')\n",
    "model_results = ModelResult(test, test_features, model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.save('bert_dpcnn_result_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = load_object('bert_dpcnn_result_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marceloblinder/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "add_predictions_to_dataframe(test, model_results.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8c7a7ca910>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test[get_label_columns(test)].sum(1).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World</td>\n",
       "      <td>0.894923</td>\n",
       "      <td>0.828612</td>\n",
       "      <td>0.860492</td>\n",
       "      <td>24144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.675801</td>\n",
       "      <td>0.697020</td>\n",
       "      <td>9050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New_York_and_Region</td>\n",
       "      <td>0.917341</td>\n",
       "      <td>0.908198</td>\n",
       "      <td>0.912746</td>\n",
       "      <td>35718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Front_Page</td>\n",
       "      <td>0.661436</td>\n",
       "      <td>0.415860</td>\n",
       "      <td>0.510658</td>\n",
       "      <td>5271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business</td>\n",
       "      <td>0.950301</td>\n",
       "      <td>0.971002</td>\n",
       "      <td>0.960540</td>\n",
       "      <td>43382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US</td>\n",
       "      <td>0.772992</td>\n",
       "      <td>0.743948</td>\n",
       "      <td>0.758192</td>\n",
       "      <td>34040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sports</td>\n",
       "      <td>0.975817</td>\n",
       "      <td>0.979133</td>\n",
       "      <td>0.977472</td>\n",
       "      <td>33546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Obituaries</td>\n",
       "      <td>0.983903</td>\n",
       "      <td>0.990961</td>\n",
       "      <td>0.987420</td>\n",
       "      <td>6970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Health</td>\n",
       "      <td>0.756335</td>\n",
       "      <td>0.676956</td>\n",
       "      <td>0.714448</td>\n",
       "      <td>7451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Education</td>\n",
       "      <td>0.698556</td>\n",
       "      <td>0.554441</td>\n",
       "      <td>0.618211</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Science</td>\n",
       "      <td>0.763334</td>\n",
       "      <td>0.675682</td>\n",
       "      <td>0.716839</td>\n",
       "      <td>4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Technology</td>\n",
       "      <td>0.704327</td>\n",
       "      <td>0.722565</td>\n",
       "      <td>0.713329</td>\n",
       "      <td>2433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Weighted Average</td>\n",
       "      <td>0.881649</td>\n",
       "      <td>0.859173</td>\n",
       "      <td>0.869258</td>\n",
       "      <td>207616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Label  Precision    Recall  F1-Score  Support\n",
       "0                 World   0.894923  0.828612  0.860492    24144\n",
       "1            Washington   0.719614  0.675801  0.697020     9050\n",
       "2   New_York_and_Region   0.917341  0.908198  0.912746    35718\n",
       "3            Front_Page   0.661436  0.415860  0.510658     5271\n",
       "4              Business   0.950301  0.971002  0.960540    43382\n",
       "5                    US   0.772992  0.743948  0.758192    34040\n",
       "6                Sports   0.975817  0.979133  0.977472    33546\n",
       "7            Obituaries   0.983903  0.990961  0.987420     6970\n",
       "8                Health   0.756335  0.676956  0.714448     7451\n",
       "9             Education   0.698556  0.554441  0.618211     1396\n",
       "10              Science   0.763334  0.675682  0.716839     4215\n",
       "11           Technology   0.704327  0.722565  0.713329     2433\n",
       "12     Weighted Average   0.881649  0.859173  0.869258   207616"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results.get_results_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8c8c959dd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_results.get_results_dataframe().plot.barh(x='Label', y='Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8cbe1e1110>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'x':((model_results.labels == model_results.predictions).astype(int).sum(1))}).plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ns2V0n20FRwh"
   },
   "source": [
    "## Saving the model\n",
    "\n",
    "* [pytorch](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
    "\n",
    "* [Google Drive](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=D78AM1fFt2ty)\n",
    "\n",
    "## Bert\n",
    "\n",
    "* [Bert Tutorial (Hidden Layers)](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/)\n",
    "\n",
    "* [GIT Huggingface](https://github.com/huggingface/transformers/blob/master/transformers/modeling_bert.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TorchBert 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
