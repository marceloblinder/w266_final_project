{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "Sz5dMqVoLWQA",
    "outputId": "8ae43beb-a0b1-4d9c-983e-91f00c2e11a5"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import logging as log\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "from transformers.models.bert.modeling_bert import BertEmbeddings, BertModel, BertPreTrainedModel\n",
    "from transformers import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    filename='bert_dpcnn.log')\n",
    "logger = log.getLogger('bert_dpcnn.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FN0GUySc2zxf",
    "outputId": "76915fd6-da91-4953-e73c-1c98331149fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla K80'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions to load/save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SgJMUdJuCavo"
   },
   "outputs": [],
   "source": [
    "root_folder = '../bert'\n",
    "\n",
    "def save_model(model, model_filename, folder=root_folder):\n",
    "    ''' Save a pytorch model '''\n",
    "    model_file = os.path.join(folder, model_filename)\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        os.remove(model_file)\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "\n",
    "def load_model(model_filename, folder=root_folder):\n",
    "    ''' Load a pytorch model '''\n",
    "    model_file = os.path.join(folder, model_filename)\n",
    "    model = torch.load(model_filename)\n",
    "\n",
    "    if is_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    return model\n",
    "\n",
    "def remove_last_model(folder, model_filename, config_filename):\n",
    "    model_file = os.path.join(folder, model_filename)\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        os.remove(model_file)\n",
    "\n",
    "    config_file = os.path.join(folder, config_filename)\n",
    "\n",
    "    if os.path.exists(config_file):\n",
    "        os.remove(config_file)\n",
    "\n",
    "def file_exists(filename, folder=root_folder):\n",
    "    return os.path.exists(os.path.join(folder, filename))\n",
    "\n",
    "def save_object(filename, obj, folder=root_folder):\n",
    "    obj_file = os.path.join(folder, filename)\n",
    "\n",
    "    if os.path.exists(obj_file):\n",
    "        os.remove(obj_file)\n",
    "\n",
    "    with open(obj_file, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_object(filename, folder=root_folder):\n",
    "    object_file = os.path.join(folder, filename)\n",
    "\n",
    "    with open(object_file, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "z3fJqCe-puL0",
    "outputId": "492ad161-0504-44d3-b55e-f671bf69d91d"
   },
   "outputs": [],
   "source": [
    "model_class = BertModel\n",
    "tokenizer_class = BertTokenizer\n",
    "pretrained_weights = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input (text) processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPPFrVtV996R"
   },
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, labels=None):\n",
    "        \"\"\"Constructs a InputExample.\"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.labels = labels\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUKr9OU59-PE"
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, label_list, max_seq_length):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    features = []\n",
    "    count = 0\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "    for example in examples:\n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "\n",
    "        if len(tokens_a) > max_seq_length - 2:\n",
    "            tokens_a = tokens_a[:(max_seq_length - 2)]\n",
    "\n",
    "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
    "        segment_ids = [0] * len(tokens)\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "        \n",
    "        labels_ids = [float(label) for label in example.labels]\n",
    "        features.append(InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_ids=labels_ids))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GZjUNwB3aRl"
   },
   "outputs": [],
   "source": [
    "# Load the full dataset into a DataFrame\n",
    "df = pd.read_parquet('../data/nyt.2000.parquet.gz')\n",
    "SEED = 17\n",
    "train, test = train_test_split(df, test_size=.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Uq4Q6rD_3lJV",
    "outputId": "0642bb9d-0978-47d7-b49e-f8579a6aeec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25716\n",
      "6430\n"
     ]
    }
   ],
   "source": [
    "print(len(train.Id))\n",
    "print(len(test.Id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZG2AW2naOOmT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing labels\n",
      "Processing examples\n",
      "Converting examples to features\n",
      "Processing labels\n",
      "Processing examples\n",
      "Converting examples to features\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LENGTH = 128\n",
    "label_columns = [c for c in train.columns if c not in ['Id', 'Text']]\n",
    "\n",
    "def get_labels(data, i):\n",
    "    return data.iloc[i][label_columns]\n",
    "\n",
    "def create_features(data, max_seq_length=MAX_SEQ_LENGTH):\n",
    "    ''' Create the features for the BERT model '''\n",
    "    \n",
    "    print('Processing labels')\n",
    "    #label_list = [get_labels(data, i) for i in range(len(data))]\n",
    "    label_list = data[label_columns].values.tolist()\n",
    "    print('Processing examples')\n",
    "    examples = [InputExample(i, data.iloc[i].Text, labels=label_list[i]) for i in range(len(data))]\n",
    "    print('Converting examples to features')\n",
    "\n",
    "    return convert_examples_to_features(examples, label_list, max_seq_length)\n",
    "\n",
    "def get_features(data, filename):\n",
    "    ''' Create the features to the model '''\n",
    "    \n",
    "    if file_exists(filename):\n",
    "        features = load_object(filename)\n",
    "    else:\n",
    "        features = create_features(data)\n",
    "        save_object(filename, features)\n",
    "\n",
    "    return features\n",
    "\n",
    "train_features = get_features(train, 'train_bert_features.pkl')\n",
    "test_features = get_features(test, 'test_bert_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4AjFtP_81D1"
   },
   "outputs": [],
   "source": [
    "class DPCNN(nn.Module):\n",
    "    ''' Class used to create the DPCNN '''\n",
    "    def __init__(self, num_labels, channel_size=250, width=768):\n",
    "        super(DPCNN, self).__init__()\n",
    "        self.conv_embedding = nn.Conv2d(1, channel_size, (3, width))\n",
    "        self.conv2 = nn.Conv2d(channel_size, channel_size, (3, 1))\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=(3,1), stride=2)\n",
    "        self.padding_conv = nn.ZeroPad2d((0, 0, 1, 1))\n",
    "        self.padding_pool = nn.ZeroPad2d((0, 0, 0, 1))\n",
    "        self.activation_function = nn.ReLU()\n",
    "        self.last_linear = nn.Linear(channel_size, num_labels)\n",
    "        self.channel_size = channel_size\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        # Expected 4-dimensional input for 4-dimensional weight 3 1 3 768, but got 2-dimensional input of size [32, 768] instead\n",
    "        batch_size, width, height = embeddings.shape\n",
    "\n",
    "        # First transform the BERT embeddings (batch_size, num_characters, 768),\n",
    "        # like (64, 80, 768)\n",
    "        # to a 4D tensor like [64, 1, 80, 768] (required by the Conv2d)\n",
    "        x = embeddings.view((batch_size, 1, width, height))\n",
    "\n",
    "        # Run the first convolution (embedding). The output is [64, 250, 78, 1] \n",
    "        x = self.conv_embedding(x)\n",
    "        #print(f'1 {x.shape}')        \n",
    "        #x = self.activation_function(x)\n",
    "        x_save = x\n",
    "\n",
    "        # Run the second convolution. The output is [64, 250, 76, 1]\n",
    "        x = self.conv2(x)\n",
    "        #print(f'2 {x.shape}')\n",
    "\n",
    "        # Add padding at starting and ending rows of the tensor. After that the\n",
    "        # shape will be [64, 250, 78, 1]\n",
    "        x = self.padding_conv(x)\n",
    "        #x = self.activation_function(x)\n",
    "\n",
    "        # Run another convolution. After that the shape will be [64, 250, 76, 1]\n",
    "        x = self.conv2(x)\n",
    "        x = self.padding_conv(x)\n",
    "        x = x + self.activation_function(x_save)\n",
    "        #print(f'3 {x.shape}')\n",
    "\n",
    "        # Go over the blocks\n",
    "        while x.shape[-2] >= 2:\n",
    "            #print(x.shape)\n",
    "            x = self.padding_pool(x)\n",
    "            #print(f'3.1 {x.shape}')\n",
    "\n",
    "            # Save the pool output to add that to the convolutions at the end\n",
    "            pooling_x = self.pooling(x) \n",
    "            #print(f'pooling {pooling_x.shape}')\n",
    "\n",
    "            # Perform the first convolution\n",
    "            x = self.padding_conv(pooling_x)\n",
    "            x = nn.functional.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            #print(f'4 {x.shape}')\n",
    "\n",
    "            # Perform the second convolution\n",
    "            x = self.padding_conv(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            #print(f'5 {x.shape}')\n",
    "\n",
    "            # Do the addition \n",
    "            x = x + pooling_x\n",
    "\n",
    "        x = x.view(batch_size, self.channel_size)\n",
    "        x = self.last_linear(x)\n",
    "         \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p6o0cIOz2nyf"
   },
   "outputs": [],
   "source": [
    "class BertFull(nn.Module):\n",
    "    \"\"\"BERT model for multiple label classification.\"\"\"\n",
    "    def __init__(self, num_labels, hidden_dropout_prob=.5):\n",
    "        super(BertFull, self).__init__()\n",
    "        num_labels = len(label_columns)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel.from_pretrained(pretrained_weights)\n",
    "        self.dropout = torch.nn.Dropout(hidden_dropout_prob)\n",
    "        self.dpcnn = DPCNN(num_labels)\n",
    "        self.classifier = torch.nn.Linear(num_labels, num_labels)\n",
    "        self.loss_fct = BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        pooled_output, _ = self.bert(input_ids, token_type_ids, attention_mask, return_dict=False)\n",
    "        x = self.dropout(pooled_output) # pooled_output\n",
    "        x = self.dpcnn(x)\n",
    "\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        if labels is not None: \n",
    "            # Training the model     \n",
    "            return self.loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "        \n",
    "        else:\n",
    "            return logits\n",
    "            \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loader for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPqLF-ikWCAW"
   },
   "outputs": [],
   "source": [
    "batch_num = 40 #48\n",
    "\n",
    "def create_input_ids_tensor(data_features):\n",
    "    return torch.tensor([i.input_ids for i in data_features])\n",
    "\n",
    "def create_input_masks_tensor(data_features):\n",
    "    return torch.tensor([i.input_mask for i in data_features])\n",
    "\n",
    "def create_segment_ids_tensor(data_features):\n",
    "    return torch.tensor([i.segment_ids for i in data_features])\n",
    "\n",
    "def create_label_ids_tensor(data_features):\n",
    "    return torch.tensor([i.label_ids for i in data_features])\n",
    "\n",
    "def create_data_loader(data_features, batch_size=batch_num, drop_last=True, shuffle=True):\n",
    "    dataset = TensorDataset(\n",
    "      create_input_ids_tensor(data_features),\n",
    "      create_input_masks_tensor(data_features),\n",
    "      create_segment_ids_tensor(data_features),\n",
    "      create_label_ids_tensor(data_features))\n",
    "    sampler = RandomSampler(dataset)\n",
    "\n",
    "    return DataLoader(dataset, sampler=sampler, batch_size=batch_size,drop_last=drop_last) if shuffle else DataLoader(dataset, batch_size=batch_size,drop_last=drop_last, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lGl6pNGteBoJ",
    "outputId": "5b99b946-7416-4405-8ea4-c43dcc09f2d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertFull(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (dpcnn): DPCNN(\n",
       "    (conv_embedding): Conv2d(1, 250, kernel_size=(3, 768), stride=(1, 1))\n",
       "    (conv2): Conv2d(250, 250, kernel_size=(3, 1), stride=(1, 1))\n",
       "    (pooling): MaxPool2d(kernel_size=(3, 1), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (padding_conv): ZeroPad2d(padding=(0, 0, 1, 1), value=0.0)\n",
       "    (padding_pool): ZeroPad2d(padding=(0, 0, 0, 1), value=0.0)\n",
       "    (activation_function): ReLU()\n",
       "    (last_linear): Linear(in_features=250, out_features=12, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=12, out_features=12, bias=True)\n",
       "  (loss_fct): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_weights = 'bert-base-uncased'\n",
    "model = BertFull(len(train.columns) - 2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9mLA1Oug7iL"
   },
   "outputs": [],
   "source": [
    "# Set epoch and grad max num\n",
    "epochs = 3\n",
    "max_grad_norm = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Yg9g2EWEhXWw",
    "outputId": "6001ea12-9b73-44a9-d45b-400aef0a6380"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertFull(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (dpcnn): DPCNN(\n",
       "    (conv_embedding): Conv2d(1, 250, kernel_size=(3, 768), stride=(1, 1))\n",
       "    (conv2): Conv2d(250, 250, kernel_size=(3, 1), stride=(1, 1))\n",
       "    (pooling): MaxPool2d(kernel_size=(3, 1), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (padding_conv): ZeroPad2d(padding=(0, 0, 1, 1), value=0.0)\n",
       "    (padding_pool): ZeroPad2d(padding=(0, 0, 0, 1), value=0.0)\n",
       "    (activation_function): ReLU()\n",
       "    (last_linear): Linear(in_features=250, out_features=12, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=12, out_features=12, bias=True)\n",
       "  (loss_fct): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine tune model all layer parameters\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "      'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "      'weight_decay_rate': 0.0}\n",
    "]\n",
    "    \n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Y0goKuhf_K7"
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "def calculate_loss(model):\n",
    "    ''' Calculate the loss on the test set for the model '''\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        num_examples = 0\n",
    "\n",
    "        for steps, batch in enumerate(create_data_loader(test_features)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            batch_input_ids, batch_input_masks, batch_segment_ids, batch_labels = batch\n",
    "            loss = model(batch_input_ids, batch_segment_ids, batch_input_masks, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "            num_examples += batch_input_ids.size(0)\n",
    "\n",
    "        return total_loss / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "excBpkTgiHHo",
    "outputId": "97ddea63-4755-444d-ebdc-37eb98539980"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.004208546242679577, test loss: 0.0028950333665125074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 1/3 [18:35<37:11, 1115.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0023390051753570634, test loss: 0.0024627379758749156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 2/3 [37:15<18:37, 1117.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0018410362787776833, test loss: 0.002482002207543701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 3/3 [55:54<00:00, 1118.25s/it]\n"
     ]
    }
   ],
   "source": [
    "# Main Training loop \n",
    "for i in trange(epochs,desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    num_examples, num_steps = 0, 0\n",
    "    \n",
    "    # Loop over the batches    \n",
    "    for step, batch in enumerate(create_data_loader(train_features)):\n",
    "        logger.info(f'Starting step {step}')\n",
    "        \n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_masks, b_segment_ids, b_labels = batch\n",
    "        \n",
    "        # forward pass\n",
    "        outputs= model(b_input_ids, b_segment_ids, b_input_masks, b_labels)\n",
    "        loss = outputs\n",
    "        \n",
    "        if n_gpu>1:\n",
    "            # When multi gpu, average it\n",
    "            loss = loss.mean()\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        num_examples += b_input_ids.size(0)\n",
    "        num_steps += 1\n",
    "        \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    # print train loss per epoch\n",
    "    train_losses.append(tr_loss / num_examples)\n",
    "    test_losses.append(calculate_loss(model))\n",
    "    save_object('train_losses_bert_dpcnn.pkl', train_losses)\n",
    "    save_object('test_losses_bert_dpcnn.pkl', test_losses)\n",
    "    logger.info(f'Train loss: {train_losses[-1]}, test loss: {test_losses[-1]}') \n",
    "    print(f'Train loss: {train_losses[-1]}, test loss: {test_losses[-1]}')\n",
    "    logger.info(f'Saving the model for the epoch {i}')\n",
    "    save_model(model, 'bert_dpcnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='x'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'x':list(range(1, len(train_losses) + 1)), 'train':train_losses, 'dev':test_losses}).plot(x='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confusion_matrix(features, model, batch_size):\n",
    "    ''' Calculate the confusion matrix for the labels of the model '''\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(create_data_loader(features, drop_last=False, shuffle=False)):\n",
    "            # add batch to gpu\n",
    "            batch = tuple(t.to('cuda') for t in batch)\n",
    "            b_input_ids, b_input_masks, b_segment_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            raw_outputs = model(b_input_ids, b_segment_ids, b_input_masks)\n",
    "            predictions.append((torch.sigmoid(raw_outputs) > .5).cpu().numpy().astype(int))\n",
    "            true_labels.append(b_labels.cpu().numpy().astype(int))\n",
    "\n",
    "        true_labels = np.vstack(true_labels)[0:(batch_size * len(predictions)),]\n",
    "        predictions = np.vstack(predictions)\n",
    "\n",
    "        return (multilabel_confusion_matrix(true_labels, predictions),\n",
    "                true_labels,\n",
    "                predictions)\n",
    "    \n",
    "def print_pct_correct(features, model):\n",
    "    tmp = calculate_confusion_matrix(features, model, 80)\n",
    "    print(f'Percentage correct {((tmp[1] == tmp[2]).astype(int).sum(1) == 12).sum() / tmp[1].shape[0]}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IYn6pn4A58nQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct 0.8020687509721575\n"
     ]
    }
   ],
   "source": [
    "print_pct_correct(train_features, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct 0.6891135303265941\n"
     ]
    }
   ],
   "source": [
    "print_pct_correct(test_features, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename, folder=root_folder):\n",
    "    ''' Load the save model '''\n",
    "    model = BertFull(len(train.columns) - 2)\n",
    "        \n",
    "    if n_gpu != 0:\n",
    "        state = torch.load(os.path.join(folder, filename))        \n",
    "        model.load_state_dict(state)        \n",
    "        model.cuda()\n",
    "    else:\n",
    "        state = torch.load(os.path.join(folder, filename), map_location=torch.device('cpu'))             \n",
    "        model.load_state_dict(state)\n",
    "      \n",
    "    return model\n",
    "\n",
    "def calculate_confusion_matrix2(features, model, batch_size):\n",
    "    ''' Calculate the confusion matrix from a trained model '''\n",
    "    \n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(create_data_loader(features, batch_size, False, False)):\n",
    "            # add batch to gpu\n",
    "            if n_gpu != 0:\n",
    "                batch = tuple(t.to('cuda') for t in batch)\n",
    "            \n",
    "            logger.info(f'Step {step}')\n",
    "            b_input_ids, b_input_masks, b_segment_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            raw_outputs = model(b_input_ids, b_segment_ids, b_input_masks)\n",
    "            predictions.append((torch.sigmoid(raw_outputs[2]) > .5).cpu().numpy().astype(int))\n",
    "            true_labels.append(b_labels.cpu().numpy().astype(int))\n",
    "\n",
    "        true_labels = np.vstack(true_labels)[0:(batch_size * len(predictions)),]\n",
    "        predictions = np.vstack(predictions)\n",
    "\n",
    "        return (multilabel_confusion_matrix(true_labels, predictions),\n",
    "                true_labels,\n",
    "                predictions)\n",
    "\n",
    "def calculate_predictions(features, model, batch_size):\n",
    "    ''' Calculate the prediction from a trained model '''\n",
    "    \n",
    "    if n_gpu != 0:\n",
    "        model.cuda()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()\n",
    "    result = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(create_data_loader(features, batch_size, False, False)):\n",
    "            logger.info(f'Step {step}')\n",
    "            \n",
    "            # add batch to gpu\n",
    "            if n_gpu != 0:\n",
    "                batch = tuple(t.to('cuda') for t in batch)\n",
    "                \n",
    "            b_input_ids, b_input_masks, b_segment_ids, b_labels = batch\n",
    "        \n",
    "            # forward pass\n",
    "            raw_outputs = model(b_input_ids, b_segment_ids, b_input_masks)\n",
    "            predictions = torch.sigmoid(raw_outputs[2]).cpu()\n",
    "            predictions = predictions.numpy()\n",
    "            result = predictions if result is None else np.append(result, predictions, axis=0)\n",
    "            \n",
    "        return result\n",
    "\n",
    "def get_label_columns(data_frame):\n",
    "    ''' Return the columns with labels from the dataframe '''\n",
    "    return [c for c in data_frame.columns if c not in ('Id', 'Text') and '_Pred' not in c]\n",
    "\n",
    "def add_predictions(data_frame, features, model, batch_size):\n",
    "    ''' Calculate and add the predicted values to the dataframe '''\n",
    "    logits = calculate_predictions(features, model, batch_size)\n",
    "    predictions = (logits > .5).astype(int)\n",
    "    \n",
    "    for i, column_name in enumerate(get_label_columns(data_frame)):\n",
    "        data_frame[f'{column_name}_Pred'] = predictions[:, i]\n",
    "\n",
    "def add_predictions_to_dataframe(data_frame, predictions):\n",
    "    ''' Add the model prediction to the dataframe '''\n",
    "    \n",
    "    for i, column_name in enumerate(get_label_columns(data_frame)):\n",
    "        data_frame[f'{column_name}_Pred'] = predictions[:, i]\n",
    "        \n",
    "class ModelResult:\n",
    "    ''' Helper class used to make prediction from a trained model '''\n",
    "\n",
    "    def __init__(self, data_frame, features, model, batch_size):\n",
    "        confusion_matrix, labels, predictions = calculate_confusion_matrix(features, model, batch_size)\n",
    "        self.confusion_matrix = confusion_matrix\n",
    "        self.labels = labels\n",
    "        self.predictions = predictions\n",
    "        self.label_columns = get_label_columns(data_frame)\n",
    "        \n",
    "    def save(self, filename):\n",
    "        ''' Save the model results (this object) to disk '''\n",
    "        save_object(filename, self)\n",
    "        \n",
    "    def get_classification_report(self, output_dictionary):\n",
    "        ''' Return the classification report from the model predictions '''\n",
    "        \n",
    "        return classification_report(self.labels, self.predictions, \n",
    "                                     target_names=self.label_columns, \n",
    "                                     output_dict=output_dictionary)\n",
    "        \n",
    "    def get_results_dataframe(self):\n",
    "        ''' Create a summary dataframe with the results from the model '''\n",
    "        \n",
    "        report_dict = self.get_classification_report(True)\n",
    "        label_columns = list(self.label_columns)\n",
    "        label_columns.append('weighted avg')\n",
    "        classification_results = pd.DataFrame({'Label':label_columns})\n",
    "        classification_results['Precision'] = [report_dict[c]['precision'] for c in label_columns]\n",
    "        classification_results['Recall'] = [report_dict[c]['recall'] for c in label_columns]\n",
    "        classification_results['F1-Score'] = [report_dict[c]['f1-score'] for c in label_columns]\n",
    "        classification_results['Support'] = [report_dict[c]['support'] for c in label_columns]\n",
    "        classification_results.loc[classification_results['Label'] == 'weighted avg', 'Label'] = 'Weighted Average'\n",
    "        \n",
    "        return classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('bert_dpcnn.pt', '../bert')\n",
    "model_results = ModelResult(test, test_features, model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.save('bert_dpcnn_result_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = load_object('bert_dpcnn_result_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-35f7139977be>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[f'{column_name}_Pred'] = predictions[:, i]\n"
     ]
    }
   ],
   "source": [
    "add_predictions_to_dataframe(test, model_results.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test[get_label_columns(test)].sum(1).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World</td>\n",
       "      <td>0.829955</td>\n",
       "      <td>0.831828</td>\n",
       "      <td>0.830891</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington</td>\n",
       "      <td>0.723042</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.784966</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New_York_and_Region</td>\n",
       "      <td>0.849085</td>\n",
       "      <td>0.939245</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>1827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Front_Page</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.360140</td>\n",
       "      <td>0.507389</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business</td>\n",
       "      <td>0.930905</td>\n",
       "      <td>0.862631</td>\n",
       "      <td>0.895468</td>\n",
       "      <td>859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US</td>\n",
       "      <td>0.741440</td>\n",
       "      <td>0.859542</td>\n",
       "      <td>0.796135</td>\n",
       "      <td>1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sports</td>\n",
       "      <td>0.968714</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>1694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Obituaries</td>\n",
       "      <td>0.971119</td>\n",
       "      <td>0.992620</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Health</td>\n",
       "      <td>0.788845</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.716094</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Education</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Science</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Technology</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.841328</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Weighted Average</td>\n",
       "      <td>0.842440</td>\n",
       "      <td>0.872688</td>\n",
       "      <td>0.852169</td>\n",
       "      <td>9245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Label  Precision    Recall  F1-Score  Support\n",
       "0                 World   0.829955  0.831828  0.830891      886\n",
       "1            Washington   0.723042  0.858491  0.784966      742\n",
       "2   New_York_and_Region   0.849085  0.939245  0.891892     1827\n",
       "3            Front_Page   0.858333  0.360140  0.507389      286\n",
       "4              Business   0.930905  0.862631  0.895468      859\n",
       "5                    US   0.741440  0.859542  0.796135     1965\n",
       "6                Sports   0.968714  0.987013  0.977778     1694\n",
       "7            Obituaries   0.971119  0.992620  0.981752      271\n",
       "8                Health   0.788845  0.655629  0.716094      302\n",
       "9             Education   0.652174  0.576923  0.612245       78\n",
       "10              Science   0.742424  0.765625  0.753846      192\n",
       "11           Technology   0.890625  0.797203  0.841328      143\n",
       "12     Weighted Average   0.842440  0.872688  0.852169     9245"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results.get_results_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Label'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_results.get_results_dataframe().plot.barh(x='Label', y='Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'x':((model_results.labels == model_results.predictions).astype(int).sum(1))}).plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ns2V0n20FRwh"
   },
   "source": [
    "## Saving the model\n",
    "\n",
    "* [pytorch](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
    "\n",
    "* [Google Drive](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=D78AM1fFt2ty)\n",
    "\n",
    "## Bert\n",
    "\n",
    "* [Bert Tutorial (Hidden Layers)](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/)\n",
    "\n",
    "* [GIT Huggingface](https://github.com/huggingface/transformers/blob/master/transformers/modeling_bert.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TorchBert 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
